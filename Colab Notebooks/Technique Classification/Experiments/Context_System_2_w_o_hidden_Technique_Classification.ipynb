{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Context System 2 w/o hidden Technique Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WkH2d0SLPeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49fpc1iF6jcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDlMmtRU1MDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import csv\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import pprint\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyXwpKlEWE4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "home_dir = \"gdrive/My Drive/propaganda_detection\"\n",
        "data_dir = os.path.join(home_dir, \"datasets\")\n",
        "model_dir = os.path.join(home_dir, \"model_dir\")\n",
        "if not os.path.isdir(model_dir):\n",
        "  os.mkdir(model_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H93QqgFyxL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read training articles\n",
        "def read_articles(dir_name):\n",
        "  articles = []\n",
        "  train_dir = os.path.join(data_dir, dir_name)\n",
        "  for filename in sorted(os.listdir(train_dir)):\n",
        "    myfile = open(os.path.join(train_dir, filename))\n",
        "    article = myfile.read()\n",
        "    articles.append(article)\n",
        "    myfile.close()\n",
        "  article_ids = []\n",
        "  for filename in sorted(os.listdir(train_dir)):\n",
        "    article_ids.append(filename[7:-4])\n",
        "  \n",
        "  return articles, article_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfBpePjiH_-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read training span labels \n",
        "def read_spans(mode=None):\n",
        "  spans = []\n",
        "  techniques = []\n",
        "  if mode == \"test\":\n",
        "    label_dir = os.path.join(data_dir, \"dev-task-TC-template.out\")\n",
        "  else:\n",
        "    label_dir = os.path.join(data_dir, \"train-labels-task2-technique-classification\")\n",
        "  for filename in sorted(os.listdir(label_dir)):\n",
        "    myfile = open(os.path.join(label_dir, filename))\n",
        "    tsvreader = csv.reader(myfile, delimiter=\"\\t\")\n",
        "    span = []\n",
        "    technique = []\n",
        "    for row in tsvreader:\n",
        "      span.append((int(row[2]), int(row[3])))\n",
        "      if mode == \"test\":\n",
        "        technique.append(\"Slogans\") # DUMMY\n",
        "      else:\n",
        "        technique.append(row[1])\n",
        "    myfile.close()\n",
        "    spans.append(span)\n",
        "    techniques.append(technique)\n",
        "  return spans, techniques"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9FjNDEZ4tnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read training span labels \n",
        "def read_test_spans():\n",
        "  spans = []\n",
        "  techniques = []\n",
        "  label_file = os.path.join(data_dir, \"dev-task-TC-template.out\")\n",
        "  myfile = open(label_file)\n",
        "  prev_index = -1\n",
        "  tsvreader = csv.reader(myfile, delimiter=\"\\t\")\n",
        "\n",
        "  span = []\n",
        "  technique = []\n",
        "  for row in tsvreader:\n",
        "    article_index = int(row[0])\n",
        "    if article_index != prev_index:\n",
        "      if prev_index != -1:\n",
        "        spans.append(span)\n",
        "        techniques.append(technique)\n",
        "      span = []\n",
        "      technique = []\n",
        "      span.append((int(row[2]), int(row[3])))\n",
        "      technique.append(\"Slogans\")\n",
        "      prev_index = article_index\n",
        "    else:\n",
        "      span.append((int(row[2]), int(row[3])))\n",
        "      technique.append(\"Slogans\")\n",
        "  spans.append(span)\n",
        "  techniques.append(technique)\n",
        "  return spans, techniques, "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLyM6nBECUgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_spans(article, span, technique):\n",
        "  for index, sp in enumerate(span):\n",
        "    print(technique[index], tag2idx[technique[index]], end=' - ')\n",
        "    print (article[sp[0]: sp[1]])\n",
        "  print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ72YQ3aVfKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_context(article, span, mode=None):\n",
        "  def get_num_words(sentence):\n",
        "    return len(sentence.split(' '))\n",
        "  if mode == \"title\":\n",
        "    return article.split('\\n')[0]\n",
        "  if mode == \"sentence\":\n",
        "    WORD_LEN_LIMIT = 120\n",
        "    li = span[0]\n",
        "    ri = span[1]\n",
        "    span_text = article[li: ri]\n",
        "    num_words = get_num_words(span_text)\n",
        "    if num_words >= WORD_LEN_LIMIT:\n",
        "      return span_text\n",
        "    remaining_len = WORD_LEN_LIMIT - num_words\n",
        "    lhs_words = remaining_len // 2\n",
        "    rhs_words = remaining_len - lhs_words\n",
        "    li -= 1\n",
        "    lcount = 0\n",
        "    while li >= 0 and article[li] != '\\n' and lcount < lhs_words:\n",
        "      if article[li] == ' ':\n",
        "        lcount += 1\n",
        "      li -= 1\n",
        "    ri += 1\n",
        "    rcount = 0\n",
        "    while ri < len(article) and article[ri] != '\\n' and rcount < rhs_words:\n",
        "      if article[ri] == ' ':\n",
        "        rcount += 1\n",
        "      ri += 1\n",
        "    return article[li+1: ri - 1] \n",
        "\n",
        "  return \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gKIOgezhjAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_examples(articles, spans, techniques, context_mode=None):\n",
        "  assert len(articles) == len(spans) and len(spans) == len(techniques)\n",
        "  sentences = []\n",
        "  labels = []\n",
        "  sent_contexts = []\n",
        "  for index, article in enumerate(articles):\n",
        "    span = spans[index]\n",
        "    technique = techniques[index]\n",
        "    assert len(technique) == len(span)\n",
        "    for i, sp in enumerate(span):\n",
        "      pt = tag2idx[technique[i]]\n",
        "      sentence = article[sp[0]: sp[1]]\n",
        "      sentences.append(sentence)\n",
        "      labels.append(pt)\n",
        "      context = get_context(article, sp, context_mode)\n",
        "      sent_contexts.append(context)\n",
        "  return sentences, labels, sent_contexts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuXFQT9rKaMk",
        "colab_type": "code",
        "outputId": "926d9ce0-ff5d-4ba9-a3a1-dc49f46006be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from transformers import BertForTokenClassification\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "def convert_sentence_to_input_feature(sentence, tokenizer, add_cls_sep=True, max_seq_len=150, context=None):\n",
        "  tokenized_sentence = tokenizer.encode_plus(sentence,\n",
        "                                             add_special_tokens=add_cls_sep,\n",
        "                                             max_length=max_seq_len,\n",
        "                                             pad_to_max_length=True,\n",
        "                                             return_attention_mask=True)\n",
        "  tokenized_context = tokenizer.encode_plus(context,\n",
        "                                            add_special_tokens=add_cls_sep,\n",
        "                                            max_length=max_seq_len,\n",
        "                                            pad_to_max_length=True,\n",
        "                                            return_attention_mask=True)\n",
        "  return tokenized_sentence['input_ids'], tokenized_sentence['attention_mask'], tokenized_context['input_ids'], tokenized_context['attention_mask']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1psU4R8EaoyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "def get_data(articles, spans, techniques, context_mode=None):\n",
        "  if context_mode is None:\n",
        "    context_mode = CONTEXT_MODE\n",
        "  sentences, labels, contexts = get_examples(articles, spans, techniques, context_mode=context_mode)\n",
        "  s_attention_masks = []\n",
        "  s_inputs = []\n",
        "  c_attention_masks = []\n",
        "  c_inputs = []\n",
        "  for i, sentence in enumerate(sentences):\n",
        "    s_input_ids, s_mask, c_input_ids, c_mask = convert_sentence_to_input_feature(sentence, tokenizer, context=contexts[i])\n",
        "    s_inputs.append(s_input_ids)\n",
        "    s_attention_masks.append(s_mask)\n",
        "    c_inputs.append(c_input_ids)\n",
        "    c_attention_masks.append(c_mask)\n",
        "\n",
        "  max_sent_len = 0\n",
        "  for sent in sentences:\n",
        "    sent_len = len(sent.split(' '))\n",
        "    max_sent_len = max(max_sent_len, sent_len)\n",
        "  max_context_len = 0\n",
        "  for sent in contexts:\n",
        "    sent_len = len(sent.split(' '))\n",
        "    max_context_len = max(max_context_len, sent_len)\n",
        "  print(max_sent_len, max_context_len)\n",
        "\n",
        "  s_inputs = torch.tensor(s_inputs)\n",
        "  c_inputs = torch.tensor(c_inputs)\n",
        "  labels = torch.tensor(labels)\n",
        "  s_masks = torch.tensor(s_attention_masks)\n",
        "  c_masks = torch.tensor(c_attention_masks)\n",
        "  tensor_data = TensorDataset(s_inputs, labels, s_masks, c_inputs, c_masks)\n",
        "  dataloader = DataLoader(tensor_data, batch_size=BATCH_SIZE)\n",
        "  return dataloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgR-htBfZ6RX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "def compute_metrics(preds, labels):\n",
        "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  print(metrics.confusion_matrix(labels_flat, pred_flat))\n",
        "  print(metrics.classification_report(labels_flat, pred_flat))\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N30yt03J9onb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3kXHP177efV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "class ContextualBertForSequenceClassification(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self, num_labels, ContextModel, SpanModel):\n",
        "    super(ContextualBertForSequenceClassification, self).__init__()\n",
        "    self.ContextModel = ContextModel\n",
        "    self.SpanModel = SpanModel\n",
        "    self.num_labels = num_labels\n",
        "\n",
        "    self.classifier = torch.nn.Linear(768*2, num_labels)\n",
        "    self.dropout = torch.nn.Dropout(0.1)\n",
        "  \n",
        "  def forward(\n",
        "      self,\n",
        "      span_input_ids,\n",
        "      span_attention_mask,\n",
        "      context_input_ids,\n",
        "      context_attention_mask,\n",
        "      labels=None\n",
        "  ):\n",
        "    context_outputs = self.ContextModel(\n",
        "        input_ids=context_input_ids,\n",
        "        attention_mask=context_attention_mask\n",
        "    )\n",
        "    context_outputs = context_outputs[1] # pooler output\n",
        "    span_outputs = self.SpanModel(\n",
        "        input_ids=span_input_ids,\n",
        "        attention_mask=span_attention_mask\n",
        "    )\n",
        "    span_outputs = span_outputs[1]\n",
        "\n",
        "    pooled_output = torch.cat((span_outputs, context_outputs), axis=1)\n",
        "    pooled_output = self.dropout(pooled_output)\n",
        "\n",
        "    logits = self.classifier(pooled_output)\n",
        "    outputs = (logits,)\n",
        "    if labels is not None:\n",
        "      if self.num_labels == 1:\n",
        "        loss_fct = MSELoss()\n",
        "        loss = loss_fct(logits.view(-1), labels.view(-1))\n",
        "      else:\n",
        "        loss_fct = CrossEntropyLoss()\n",
        "        loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "      outputs = (loss,) + outputs\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uCzVrHKdCj0s",
        "colab": {}
      },
      "source": [
        "def train(model, epochs=5):\n",
        "  loss_values = []\n",
        "  for epoch_i in range(0, epochs):\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "      if step % 100 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_labels = batch[1].to(device)\n",
        "      b_input_mask = batch[2].to(device)\n",
        "      b_c_input_ids = batch[3].to(device)\n",
        "      b_c_input_mask = batch[4].to(device)\n",
        "      model.zero_grad()        \n",
        "      outputs = model(b_input_ids, \n",
        "                      b_input_mask,\n",
        "                      b_c_input_ids, \n",
        "                      b_c_input_mask, \n",
        "                      labels=b_labels)\n",
        "      loss = outputs[0]\n",
        "      total_loss += loss.item()\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "      optimizer.step()\n",
        "      scheduler.step() # TODO\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    loss_values.append(avg_train_loss)\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    for batch in eval_dataloader:\n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_labels = batch[1].to(device)\n",
        "      b_input_mask = batch[2].to(device)\n",
        "      b_c_input_ids = batch[3].to(device)\n",
        "      b_c_input_mask = batch[4].to(device)\n",
        "      with torch.no_grad():        \n",
        "        outputs = model(b_input_ids, \n",
        "                        b_input_mask,\n",
        "                        b_c_input_ids, \n",
        "                        b_c_input_mask)\n",
        "      logits = outputs[0]\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = b_labels.to('cpu').numpy()\n",
        "      tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "      eval_accuracy += tmp_eval_accuracy\n",
        "      nb_eval_steps += 1\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "  print(\"\")\n",
        "  print(\"Training complete!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOW1nliOdVKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model_predictions(model, dataloader):\n",
        "  model.eval()\n",
        "  predictions , true_labels = [], []\n",
        "  nb_eval_steps = 0\n",
        "  for batch in dataloader:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_labels = batch[1].to(device)\n",
        "    b_input_mask = batch[2].to(device)\n",
        "    b_c_input_ids = batch[3].to(device)\n",
        "    b_c_input_mask = batch[4].to(device)\n",
        "    with torch.no_grad():        \n",
        "      logits = model(b_input_ids, \n",
        "                     b_input_mask,\n",
        "                     b_c_input_ids, \n",
        "                     b_c_input_mask)\n",
        "    logits = logits[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    pred_label = np.argmax(logits, axis=1)\n",
        "    predictions.extend(pred_label)\n",
        "    true_labels.extend(label_ids)\n",
        "  return predictions, true_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs-aNAVK5Ina",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "def get_dev_predictions(model):\n",
        "  test_articles, _ = read_articles(\"dev-articles\")\n",
        "  test_spans, test_techniques = read_test_spans()\n",
        "\n",
        "  test_articles = test_articles[1:]\n",
        "  test_dataloader = get_data(test_articles, test_spans, test_techniques)\n",
        "  pred, _ = get_model_predictions(model, test_dataloader)\n",
        "\n",
        "  with open('predictions.txt', 'w') as fp:\n",
        "    label_file = os.path.join(data_dir, \"dev-task-TC-template.out\")\n",
        "    myfile = open(label_file)\n",
        "    prev_index = -1\n",
        "    tsvreader = csv.reader(myfile, delimiter=\"\\t\")\n",
        "    for i, row in enumerate(tsvreader):\n",
        "      fp.write(row[0] + '\\t' + distinct_techniques[pred[i]] + '\\t' + row[2] + '\\t' + row[3] + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuUfhq4EhjKL",
        "colab_type": "code",
        "outputId": "ba6a69c5-6721-4a04-c748-708fb0670a22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer\n",
        "from transformers import RobertaTokenizer\n",
        "\n",
        "articles, article_ids = read_articles(\"train-articles\")\n",
        "spans, techniques = read_spans()\n",
        "distinct_techniques = list(set([y for x in techniques for y in x])) # idx to tag\n",
        "tag2idx = {t: i for i, t in enumerate(distinct_techniques)}\n",
        "pprint.pprint(tag2idx)\n",
        "\n",
        "NUM_ARTICLES = len(articles)\n",
        "\n",
        "articles = articles[0:NUM_ARTICLES]\n",
        "spans = spans[0:NUM_ARTICLES]\n",
        "techniques = techniques[0:NUM_ARTICLES]\n",
        "BATCH_SIZE=8\n",
        "\n",
        "seed_val = 1328\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "indices = np.arange(NUM_ARTICLES)\n",
        "test_size = 0.1\n",
        "train_articles, eval_articles, train_spans, eval_spans, train_techniques, eval_techniques, train_indices, eval_indices = train_test_split(articles, spans, techniques, indices, test_size=test_size)\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', lower_case=True)\n",
        "\n",
        "CONTEXT_MODE = \"sentence\" # sentence or title\n",
        "\n",
        "train_dataloader = get_data(train_articles, train_spans, train_techniques)\n",
        "eval_dataloader = get_data(eval_articles, eval_spans, eval_techniques)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Appeal_to_Authority': 4,\n",
            " 'Appeal_to_fear-prejudice': 6,\n",
            " 'Bandwagon,Reductio_ad_hitlerum': 1,\n",
            " 'Black-and-White_Fallacy': 7,\n",
            " 'Causal_Oversimplification': 5,\n",
            " 'Doubt': 9,\n",
            " 'Exaggeration,Minimisation': 10,\n",
            " 'Flag-Waving': 12,\n",
            " 'Loaded_Language': 2,\n",
            " 'Name_Calling,Labeling': 3,\n",
            " 'Repetition': 0,\n",
            " 'Slogans': 11,\n",
            " 'Thought-terminating_Cliches': 13,\n",
            " 'Whataboutism,Straw_Men,Red_Herring': 8}\n",
            "133 133\n",
            "93 93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrEXyRFf8uad",
        "colab_type": "code",
        "outputId": "03c34b9d-9199-41f1-f34e-d7cb8e482c18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import RobertaModel\n",
        "from transformers import BertModel\n",
        "from transformers import RobertaForSequenceClassification\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_labels = len(distinct_techniques)\n",
        "\n",
        "context_model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "span_model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "model = ContextualBertForSequenceClassification(num_labels, context_model, span_model)\n",
        "model.cuda()\n",
        "\n",
        "optimizer = AdamW(model.parameters(),lr = 3e-5,eps = 1e-8) # ler = 5e-5\n",
        "epochs = 3\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "train(model, epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch   100  of    691.    Elapsed: 0:01:05.\n",
            "  Batch   200  of    691.    Elapsed: 0:02:10.\n",
            "  Batch   300  of    691.    Elapsed: 0:03:15.\n",
            "  Batch   400  of    691.    Elapsed: 0:04:20.\n",
            "  Batch   500  of    691.    Elapsed: 0:05:25.\n",
            "  Batch   600  of    691.    Elapsed: 0:06:30.\n",
            "\n",
            "  Average training loss: 1.71\n",
            "  Training epcoh took: 0:07:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.68\n",
            "  Validation took: 0:00:13\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch   100  of    691.    Elapsed: 0:01:05.\n",
            "  Batch   200  of    691.    Elapsed: 0:02:10.\n",
            "  Batch   300  of    691.    Elapsed: 0:03:16.\n",
            "  Batch   400  of    691.    Elapsed: 0:04:21.\n",
            "  Batch   500  of    691.    Elapsed: 0:05:26.\n",
            "  Batch   600  of    691.    Elapsed: 0:06:32.\n",
            "\n",
            "  Average training loss: 1.17\n",
            "  Training epcoh took: 0:07:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.71\n",
            "  Validation took: 0:00:13\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch   100  of    691.    Elapsed: 0:01:05.\n",
            "  Batch   200  of    691.    Elapsed: 0:02:11.\n",
            "  Batch   300  of    691.    Elapsed: 0:03:16.\n",
            "  Batch   400  of    691.    Elapsed: 0:04:21.\n",
            "  Batch   500  of    691.    Elapsed: 0:05:26.\n",
            "  Batch   600  of    691.    Elapsed: 0:06:32.\n",
            "\n",
            "  Average training loss: 0.87\n",
            "  Training epcoh took: 0:07:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.72\n",
            "  Validation took: 0:00:12\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G1S-4ZZOI3v",
        "colab_type": "code",
        "outputId": "73ea13c5-4d99-4023-bb73-fe3069aa16eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_dev_predictions(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80 98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71ZJtz2oQdQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('predictions.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuWJr2eS9KRG",
        "colab_type": "code",
        "outputId": "c7c01fb0-bc04-4a05-984d-fe64d3047cb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "s, t = get_model_predictions(model, train_dataloader)\n",
        "print (len(s), len(t))\n",
        "print(metrics.confusion_matrix(t, s))\n",
        "print(metrics.classification_report(t, s))\n",
        "\n",
        "s, t = get_model_predictions(model, eval_dataloader)\n",
        "print (len(s), len(t))\n",
        "print(metrics.confusion_matrix(t, s))\n",
        "print(metrics.classification_report(t, s))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5679 5679\n",
            "[[ 383    0    1    1    5   22    1    1    3    5    0    2    1    1]\n",
            " [   1  104    0    1   14    1    1    2    7    1    1    1    0    0]\n",
            " [   1    0  110    0    0    1    0    0    5    0    0    2    0    0]\n",
            " [   0    2    0  183    3    1    3    0    0    0    3    1    1    1]\n",
            " [   3    2    3    3  226   11    0    2    6    1    2    2    1    0]\n",
            " [  38    0    4    2    7 1852    2    0   13   18    0    4    0    0]\n",
            " [   4    1    0    9    1    2  423    0    2    2    0    3    0    2]\n",
            " [   2    0    2    3    0    6    0   54    0    0    2    0    0    0]\n",
            " [   5    4   11    0    3   52    4    3  466   31    2   16    0    0]\n",
            " [   3    0    0    0    0   30    1    0   12  959    0    0    2    0]\n",
            " [   1    0    0    5    8    0    1    4    0    0   78    2    1    0]\n",
            " [   0    1    4    2    2    0    2    0    0    1    1  204    0    0]\n",
            " [   2    8    0    8    1    0    1    0    0    1    7    1   36    1]\n",
            " [   0    7    0    7    3    0   18    0    3    2    3    3    5   44]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.90      0.88       426\n",
            "           1       0.81      0.78      0.79       134\n",
            "           2       0.81      0.92      0.87       119\n",
            "           3       0.82      0.92      0.87       198\n",
            "           4       0.83      0.86      0.84       262\n",
            "           5       0.94      0.95      0.95      1940\n",
            "           6       0.93      0.94      0.93       449\n",
            "           7       0.82      0.78      0.80        69\n",
            "           8       0.90      0.78      0.84       597\n",
            "           9       0.94      0.95      0.95      1007\n",
            "          10       0.79      0.78      0.78       100\n",
            "          11       0.85      0.94      0.89       217\n",
            "          12       0.77      0.55      0.64        66\n",
            "          13       0.90      0.46      0.61        95\n",
            "\n",
            "    accuracy                           0.90      5679\n",
            "   macro avg       0.85      0.82      0.83      5679\n",
            "weighted avg       0.90      0.90      0.90      5679\n",
            "\n",
            "450 450\n",
            "[[ 23   0   1   0   1   8   0   0   3   0   0   2   1   1]\n",
            " [  2   3   0   2   3   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   6   0   1   2   0   0   0   0   1   0   0   0]\n",
            " [  0   1   0   4   1   0   3   0   0   0   1   0   0   1]\n",
            " [  0   2   2   4  18   0   1   0   0   1   3   1   0   0]\n",
            " [ 11   0   2   2   3 142   2   0   7  10   2   2   0   0]\n",
            " [  4   1   0   4   0   4  28   0   1   0   0   1   0   1]\n",
            " [  0   0   0   0   0   0   1   6   0   0   0   0   0   0]\n",
            " [  2   0   3   1   1  10   0   0   5   1   1   0   0   0]\n",
            " [  2   0   1   0   0   7   0   0   0  40   0   1   0   0]\n",
            " [  0   0   0   0   1   0   1   0   0   0   5   0   0   0]\n",
            " [  0   0   0   0   0   0   1   0   0   0   0  11   0   0]\n",
            " [  1   1   0   0   0   0   0   0   0   0   0   0   1   3]\n",
            " [  1   0   0   0   2   0   4   0   0   0   0   1   0   5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.57      0.53        40\n",
            "           1       0.38      0.30      0.33        10\n",
            "           2       0.40      0.60      0.48        10\n",
            "           3       0.24      0.36      0.29        11\n",
            "           4       0.58      0.56      0.57        32\n",
            "           5       0.82      0.78      0.80       183\n",
            "           6       0.68      0.64      0.66        44\n",
            "           7       1.00      0.86      0.92         7\n",
            "           8       0.31      0.21      0.25        24\n",
            "           9       0.77      0.78      0.78        51\n",
            "          10       0.38      0.71      0.50         7\n",
            "          11       0.58      0.92      0.71        12\n",
            "          12       0.50      0.17      0.25         6\n",
            "          13       0.45      0.38      0.42        13\n",
            "\n",
            "    accuracy                           0.66       450\n",
            "   macro avg       0.54      0.56      0.53       450\n",
            "weighted avg       0.67      0.66      0.66       450\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}