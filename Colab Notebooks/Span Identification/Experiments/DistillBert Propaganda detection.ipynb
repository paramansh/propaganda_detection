{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DistillBert Propaganda detection.ipynb","provenance":[{"file_id":"15oan7cjDITm_FU5OJxDUZW_TFGC8FJ7z","timestamp":1585246028182}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"2WkH2d0SLPeT","colab_type":"code","outputId":"3c14e51b-e31c-4659-e719-fa77d0bb8a49","executionInfo":{"status":"ok","timestamp":1586722357109,"user_tz":-330,"elapsed":32687,"user":{"displayName":"Paramansh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFUNSFhHphbpc_SffpUNDNLqiLPYS3aiygkhnRTw=s64","userId":"05094200950482431055"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"49fpc1iF6jcS","colab_type":"code","outputId":"eeb4bddc-2297-4ec7-cc33-5662e9b920b7","executionInfo":{"status":"ok","timestamp":1586722366216,"user_tz":-330,"elapsed":41637,"user":{"displayName":"Paramansh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFUNSFhHphbpc_SffpUNDNLqiLPYS3aiygkhnRTw=s64","userId":"05094200950482431055"}},"colab":{"base_uri":"https://localhost:8080/","height":683}},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n","\r\u001b[K     |▋                               | 10kB 19.3MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 4.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 6.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 7.8MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 5.0MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 6.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 6.4MB/s \n","\u001b[?25hCollecting tokenizers==0.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n","\u001b[K     |████████████████████████████████| 3.7MB 41.1MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n","\u001b[K     |████████████████████████████████| 870kB 42.9MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 40.7MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.38)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n","Requirement already satisfied: botocore<1.16.0,>=1.15.38 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.38)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (2.8.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=114f40694b7f0e62722115d22f98acf2ad445ef98aa125b88ca5a8928cd5d9fb\n","  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.8.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SDlMmtRU1MDJ","colab_type":"code","colab":{}},"source":["import os\n","import sys\n","import torch\n","import csv\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6CIN9YGU-qY1","colab_type":"code","colab":{}},"source":["home_dir = \"gdrive/My Drive/propaganda_detection\"\n","data_dir = os.path.join(home_dir, \"datasets\")\n","model_dir = os.path.join(home_dir, \"model_dir\")\n","if not os.path.isdir(model_dir):\n","  os.mkdir(model_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-H93QqgFyxL1","colab_type":"code","colab":{}},"source":["# Read training articles\n","def read_articles(article_dir):\n","  articles = []\n","  train_dir = os.path.join(data_dir, article_dir)\n","  for filename in sorted(os.listdir(train_dir)):\n","    myfile = open(os.path.join(train_dir, filename))\n","    article = myfile.read()\n","    articles.append(article)\n","    myfile.close()\n","  article_ids = []\n","  for filename in sorted(os.listdir(train_dir)):\n","    article_ids.append(filename[7:-4])\n","  return articles, article_ids"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MfBpePjiH_-o","colab_type":"code","colab":{}},"source":["# Read training span labels \n","def read_spans():\n","  spans = []\n","  label_dir = os.path.join(data_dir, \"train-labels-task1-span-identification\")\n","  for filename in sorted(os.listdir(label_dir)):\n","    myfile = open(os.path.join(label_dir, filename))\n","    tsvreader = csv.reader(myfile, delimiter=\"\\t\")\n","    span = []\n","    for row in tsvreader:\n","      span.append((int(row[1]), int(row[2])))\n","    myfile.close()\n","    spans.append(span)\n","  return spans"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RLyM6nBECUgl","colab_type":"code","colab":{}},"source":["def print_spans(article, span):\n","  for sp in span:\n","    print (article[sp[0]: sp[1]])\n","  print()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qw8VueZ0iQ9o","colab_type":"code","colab":{}},"source":["class example_sentence:\n","  def __init__(self):\n","    self.tokens = []\n","    self.labels = []\n","    self.article_index = -1 # index of the article to which the sentence is associated\n","    self.index = -1 # index of the sentence in that article \n","    self.word_to_start_char_offset = []\n","    self.word_to_end_char_offset = []\n","  \n","  def __str__(self):\n","    print(\"tokens -\", self.tokens)\n","    print(\"labels -\", self.labels)\n","    print(\"article_index -\", self.article_index)\n","    print(\"index -\", self.index)\n","    print(\"start_offset -\", self.word_to_start_char_offset)\n","    print(\"end_offset -\", self.word_to_end_char_offset)   \n","    return \"\"    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TI57Sv2DrVQ5","colab_type":"code","colab":{}},"source":["def is_whitespace(c):\n","  if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n","    return True\n","  return False\n","\n","def get_sentence_tokens_labels(article, span=None, article_index=None):\n","  doc_tokens = []\n","  char_to_word_offset = []\n","  current_sentence_tokens = [] # actually all sentence tokens for particular article. #TODO rename\n","  word_to_start_char_offset = {}\n","  word_to_end_char_offset = {}\n","  prev_is_whitespace = True\n","  prev_is_newline = True\n","  current_word_position = None\n","  for index, c in enumerate(article):\n","    if c == \"\\n\":\n","      prev_is_newline = True\n","      # check for empty lists\n","      if doc_tokens:\n","        current_sentence_tokens.append(doc_tokens)\n","      doc_tokens = []\n","    if is_whitespace(c):\n","      prev_is_whitespace = True\n","      if current_word_position is not None:\n","        word_to_end_char_offset[current_word_position] = index\n","        current_word_position = None\n","    else:\n","      if prev_is_whitespace:\n","        doc_tokens.append(c)\n","        current_word_position = (len(current_sentence_tokens), len(doc_tokens) - 1)\n","        word_to_start_char_offset[current_word_position] = index # start offset of word\n","      else:\n","        doc_tokens[-1] += c\n","      prev_is_whitespace = False\n","    char_to_word_offset.append((len(current_sentence_tokens), len(doc_tokens) - 1))\n","  if doc_tokens:\n","    current_sentence_tokens.append(doc_tokens)\n","  if current_word_position is not None:\n","    word_to_end_char_offset[current_word_position] = index\n","    current_word_position = None\n","  if span is None:\n","    return current_sentence_tokens, (word_to_start_char_offset, word_to_end_char_offset)\n","\n","  current_propaganda_labels = []\n","  for doc_tokens in current_sentence_tokens:\n","    current_propaganda_labels.append([0] * len(doc_tokens))\n","\n","  start_positions = []\n","  end_positions = []\n","\n","  for sp in span:\n","    if (char_to_word_offset[sp[0]][0] != char_to_word_offset[sp[1]-1][0]):\n","      l1 = char_to_word_offset[sp[0]][0]\n","      l2 = char_to_word_offset[sp[1] - 1][0]\n","      start_positions.append(char_to_word_offset[sp[0]])\n","      end_positions.append((l1, len(current_sentence_tokens[l1])-1))\n","      l1 += 1\n","      while(l1 < l2):\n","        start_positions.append((l1, 0))\n","        end_positions.append((l1, len(current_sentence_tokens[l1])-1))\n","        l1 += 1\n","      start_positions.append((l2, 0))\n","      end_positions.append(char_to_word_offset[sp[1]-1])  \n","      continue\n","    start_positions.append(char_to_word_offset[sp[0]])\n","    end_positions.append(char_to_word_offset[sp[1]-1])\n","\n","  for i, s in enumerate(start_positions):\n","    assert start_positions[i][0] == end_positions[i][0]\n","    if TAGGING_SCHEME == \"BIO\":\n","      current_propaganda_labels[start_positions[i][0]][start_positions[i][1]] = 2 # Begin label\n","      if start_positions[i][1] < end_positions[i][1]:\n","        current_propaganda_labels[start_positions[i][0]][start_positions[i][1] + 1 : end_positions[i][1] + 1] = [1] * (end_positions[i][1] - start_positions[i][1])\n","    if TAGGING_SCHEME == \"BIOE\":\n","      current_propaganda_labels[start_positions[i][0]][start_positions[i][1]] = 2 # Begin label\n","      if start_positions[i][1] < end_positions[i][1]:\n","        current_propaganda_labels[start_positions[i][0]][start_positions[i][1] + 1 : end_positions[i][1]] = [1] * (end_positions[i][1] - start_positions[i][1] - 1)\n","        current_propaganda_labels[start_positions[i][0]][end_positions[i][1]] = 3 # End label\n","    else:\n","      current_propaganda_labels[start_positions[i][0]][start_positions[i][1] : end_positions[i][1] + 1] = [1] * (end_positions[i][1] + 1 - start_positions[i][1])\n","  \n","  num_sentences = len(current_sentence_tokens)\n","\n","  start_offset_list = get_list_from_dict(num_sentences, word_to_start_char_offset)\n","  end_offset_list = get_list_from_dict(num_sentences, word_to_end_char_offset)\n","  sentences = []\n","  for i in range(num_sentences):\n","    sentence = example_sentence()\n","    sentence.tokens = current_sentence_tokens[i]\n","    sentence.labels = current_propaganda_labels[i]\n","    sentence.article_index =  article_index\n","    sentence.index = i\n","    sentence.word_to_start_char_offset = start_offset_list[i]\n","    sentence.word_to_end_char_offset = end_offset_list[i]\n","    num_words = len(sentence.tokens)\n","    assert len(sentence.labels) == num_words\n","    assert len(sentence.word_to_start_char_offset) == num_words\n","    assert len(sentence.word_to_end_char_offset) == num_words\n","    sentences.append(sentence)\n","\n","  return current_sentence_tokens, current_propaganda_labels, (word_to_start_char_offset, word_to_end_char_offset), sentences"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OyvXc3mUr-Ln","colab_type":"code","colab":{}},"source":["def get_list_from_dict(num_sentences, word_offsets):\n","  li = []\n","  for _ in range(num_sentences):\n","    li.append([])\n","  for key in word_offsets:\n","    si = key[0]\n","    li[si].append(word_offsets[key])\n","\n","  return li"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cGjKxzI72CE6","colab_type":"code","colab":{}},"source":["class BertExample:\n","  def __init__(self):\n","    self.add_cls_sep = True\n","    self.sentence_id = -1\n","    self.orig_to_tok_index = []\n","    self.tok_to_orig_index = []\n","    self.labels = None\n","    self.tokens_ids = []\n","    self.input_mask = []\n","  def __str__(self):\n","    print(\"sentence_id\", self.sentence_id)\n","    return \"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iuXFQT9rKaMk","colab_type":"code","colab":{}},"source":["def convert_sentence_to_input_feature(sentence, sentence_id, tokenizer, add_cls_sep=True, max_seq_len=256):\n","  bert_example = BertExample()\n","  bert_example.sentence_id = sentence_id\n","  bert_example.add_cls_sep = add_cls_sep\n","\n","  sentence_tokens = sentence.tokens\n","  sentence_labels = sentence.labels \n","\n","  tok_to_orig_index = []\n","  orig_to_tok_index = []\n","  all_doc_tokens = [] \n","  for (i, token) in enumerate(sentence_tokens):\n","    orig_to_tok_index.append(len(all_doc_tokens))\n","    sub_tokens = tokenizer.tokenize(token)\n","    for sub_token in sub_tokens:\n","      tok_to_orig_index.append(i)\n","      all_doc_tokens.append(sub_token)\n","  bert_example.tok_to_orig_index = tok_to_orig_index\n","  bert_example.orig_to_tok_index = orig_to_tok_index\n","\n","  bert_tokens = all_doc_tokens\n","  if add_cls_sep:\n","    bert_tokens = [\"[CLS]\"] + bert_tokens\n","    bert_tokens = bert_tokens + [\"[SEP]\"]\n","  \n","  tokens_ids = tokenizer.convert_tokens_to_ids(bert_tokens)\n","  input_mask = [1] * len(tokens_ids)\n","  while len(tokens_ids) < max_seq_len:\n","    tokens_ids.append(0)\n","    input_mask.append(0)\n","  # tokens_ids = pad_sequences(tokens_ids, maxlen=max_seq_len, truncating=\"post\", padding=\"post\", dtype=\"int\")\n","  bert_example.tokens_ids = tokens_ids\n","  bert_example.input_mask = input_mask\n","  # bert_example.input_mask = [float(i>0) for i in token_ids]\n","\n","  if sentence_labels is None:\n","    return bert_example\n","  \n","\n","  labels = [0] * len(all_doc_tokens)\n","  for index, token in enumerate(all_doc_tokens):\n","    labels[index] = sentence_labels[tok_to_orig_index[index]]\n","  if add_cls_sep:\n","    labels = [0] + labels\n","    labels = labels + [0]\n","  # labels = pad_sequences(labels, maxlen=max_seq_len, truncating=\"post\", padding=\"post\", dtype=\"int\")\n","  while len(labels) < max_seq_len:\n","    labels.append(0)\n","  bert_example.labels = labels\n","\n","  return bert_example \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1psU4R8EaoyA","colab_type":"code","colab":{}},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from transformers import BertTokenizer\n","\n","def get_dataloader(examples, batch_size=8):\n","  inputs = torch.tensor([d.tokens_ids for d in examples])\n","  labels = torch.tensor([d.labels for d in examples])\n","  masks = torch.tensor([d.input_mask for d in examples])\n","  sentence_ids = torch.tensor([d.sentence_id for d in examples])\n","  tensor_data = TensorDataset(inputs, labels, masks, sentence_ids)\n","  dataloader = DataLoader(tensor_data, batch_size=BATCH_SIZE)\n","  return dataloader\n","\n","def get_data(articles, spans, indices):\n","  assert len(articles) == len(spans)    \n","  sentences = []\n","  for index in indices:\n","    article = articles[index]\n","    span = spans[index]\n","    _, _, _, cur_sentences = get_sentence_tokens_labels(article, span, index)\n","    sentences += cur_sentences\n","  print(len(sentences))\n","  print(max([len(s.tokens) for s in sentences]))\n","  bert_examples = []\n","  for i, sentence in enumerate(sentences):\n","    input_feature = convert_sentence_to_input_feature(sentence, i, tokenizer)\n","    bert_examples.append(input_feature)\n","  dataloader = get_dataloader(bert_examples, BATCH_SIZE)\n","  return dataloader, sentences, bert_examples"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BgR-htBfZ6RX","colab_type":"code","colab":{}},"source":["def flat_accuracy(preds, labels):\n","  pred_flat = np.argmax(preds, axis=2).flatten()\n","  labels_flat = labels.flatten()\n","  return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JvlqT1P_TGZc","colab_type":"code","colab":{}},"source":["from transformers import DistilBertPreTrainedModel, DistilBertModel\n","import torch.nn as nn\n","from torch.nn import CrossEntropyLoss\n","\n","class CustomBertForTokenClassification(DistilBertPreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.num_labels = config.num_labels\n","        self.my_hidden_size = 128\n","        self.bert = DistilBertModel(config)\n","        self.dropout = nn.Dropout(0)\n","        # self.my_hidden = nn.Linear(config.hidden_size, self.my_hidden_size)\n","        # self.classifier = nn.Linear(self.my_hidden_size, config.num_labels)\n","        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n","\n","        self.init_weights()\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","        position_ids=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=None,\n","    ):\n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","        )\n","\n","        sequence_output = outputs[0]\n","\n","        sequence_output = self.dropout(sequence_output)\n","        logits = self.classifier(sequence_output)\n","        # logits = self.my_hidden(sequence_output)\n","        # logits = self.classifier(logits)\n","\n","        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n","        if labels is not None:\n","            loss_fct = CrossEntropyLoss()\n","            # Only keep active parts of the loss\n","            if attention_mask is not None:\n","                active_loss = attention_mask.view(-1) == 1\n","                active_logits = logits.view(-1, self.num_labels)\n","                active_labels = torch.where(\n","                    active_loss, labels.view(-1), torch.tensor(loss_fct.ignore_index).type_as(labels)\n","                )\n","                loss = loss_fct(active_logits, active_labels)\n","            else:\n","                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","            outputs = (loss,) + outputs\n","\n","        return outputs  # (loss), scores, (hidden_states), (attentions)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ZtX5jmYUIMU","colab_type":"code","colab":{}},"source":["from tqdm import tqdm, trange\n","import time\n","import datetime\n","\n","def train(model, train_dataloader, eval_dataloader, epochs=5, save_model=False):\n","  max_grad_norm = 1.0\n","\n","  for _ in trange(epochs, desc=\"Epoch\"):\n","    # TRAIN loop\n","    model.train()\n","    tr_loss = 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    for step, batch in enumerate(train_dataloader):\n","      # add batch to gpu\n","      batch = tuple(t.to(device) for t in batch)\n","      b_input_ids, b_labels, b_input_mask, b_ids = batch\n","      loss, _ = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","      loss.backward()\n","      tr_loss += loss.item()\n","      nb_tr_examples += b_input_ids.size(0)\n","      nb_tr_steps += 1\n","      torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n","      optimizer.step()\n","      model.zero_grad()\n","    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n","\n","    get_score(model, mode=\"train\")\n","\n","    model.eval()\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","    predictions , true_labels = [], []\n","    for batch in eval_dataloader:\n","      batch = tuple(t.to(device) for t in batch)\n","      b_input_ids, b_labels, b_input_mask, b_ids = batch\n","      with torch.no_grad():\n","        tmp_eval_loss, _ = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","      # logits = logits[0]\n","      # logits = logits.detach().cpu().numpy()\n","      # label_ids = b_labels.to('cpu').numpy()\n","      # predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n","      # true_labels.append(label_ids)\n","      \n","      # tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","      \n","      eval_loss += tmp_eval_loss.mean().item()\n","      # eval_accuracy += tmp_eval_accuracy\n","      \n","      nb_eval_examples += b_input_ids.size(0)\n","      nb_eval_steps += 1\n","    eval_loss = eval_loss/nb_eval_steps\n","    print(\"Validation loss: {}\".format(eval_loss))\n","\n","    get_score(model, mode=\"eval\")\n","    if save_model:\n","      model_name = 'model_' + str(datetime.datetime.now()) + '.pt'\n","      torch.save(model, os.path.join(model_dir, model_name))\n","      print(\"Model saved:\", model_name)\n","    print()\n","    time.sleep(1)\n","    # print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n","    # pred_tags = [p_i for p in predictions for p_i in p]\n","    # valid_tags = [l_ii for l in true_labels for l_i in l for l_ii in l_i]\n","    # print(\"F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pOW1nliOdVKr","colab_type":"code","colab":{}},"source":["def get_model_predictions(model, dataloader):\n","  model.eval()\n","  predictions , true_labels, sentence_ids = [], [], []\n","  nb_eval_steps = 0\n","  for batch in dataloader:\n","    batch = tuple(t.to(device) for t in batch)\n","    b_input_ids, b_labels, b_input_mask, b_ids = batch  \n","    with torch.no_grad():\n","      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","    logits = logits[0]\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    s_ids = b_ids.to('cpu').numpy()\n","    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n","    # print(label_ids)\n","    true_labels.extend(label_ids)\n","    sentence_ids.extend(s_ids)\n","    nb_eval_steps += 1\n","  \n","  return predictions, true_labels, sentence_ids"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"974hWI4WB3lq","colab_type":"code","colab":{}},"source":["def merge_spans(current_spans):\n","  if not current_spans:\n","    return [] \n","  merged_spans = []\n","  li = current_spans[0][0]\n","  ri = current_spans[0][1]\n","  threshold = 2\n","  for i in range(len(current_spans) - 1):\n","    span = current_spans[i+1]\n","    if span[0] - ri < 2:\n","      ri = span[1]\n","      continue\n","    else:\n","      merged_spans.append((li, ri))\n","      li = span[0]\n","      ri = span[1]\n","  merged_spans.append((li, ri))\n","  return merged_spans"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZyV-2iMb8s7Y","colab_type":"code","colab":{}},"source":["from shutil import copyfile\n","def get_score(model, mode=None):\n","  predicted_spans = [[] for i in range(400)] # TODO 400 hardcoded\n","  \n","  def get_span_prediction(prediction_labels, sentence_index, sentences, bert_examples):\n","    index = sentence_index \n","    bert_example = bert_examples[index]\n","    mask = bert_example.input_mask\n","    pred_labels_masked = prediction_labels # need to change to predictions later\n","    pred_labels = []\n","    for i, m in enumerate(mask):\n","      if m > 0:\n","        pred_labels.append(pred_labels_masked[i])\n","    if bert_example.add_cls_sep:\n","      pred_labels.pop() # remove ['SEP'] label\n","      pred_labels.pop(0) # remove ['CLS'] label\n","\n","    sentence = sentences[index]\n","    sent_len = len(sentence.tokens)\n","    final_pred_labels = [0] * sent_len\n","    cur_map = bert_example.tok_to_orig_index\n","    for i, label in enumerate(pred_labels):\n","      final_pred_labels[cur_map[i]] |= label\n","    # assert final_pred_labels == sentence.labels\n","    \n","    word_start_index_map = sentence.word_to_start_char_offset\n","    word_end_index_map = sentence.word_to_end_char_offset\n","\n","    article_index = sentence.article_index\n","    for i, label in enumerate(final_pred_labels):\n","      if label:\n","        # print(word_start_index_map[i], word_end_index_map[i])\n","        predicted_spans[article_index].append((word_start_index_map[i], word_end_index_map[i]))\n","  \n","  if mode == \"train\":\n","    indices = train_indices\n","    predictions, true_labels, sentence_ids = get_model_predictions(model, train_dataloader)\n","    pred_sentences, pred_bert_examples = train_sentences, train_bert_examples\n","  elif mode == \"test\":\n","    predictions, true_labels , sentence_ids = get_model_predictions(model, test_dataloader)\n","    pred_sentences, pred_bert_examples = test_sentences, test_bert_examples\n","  else:\n","    indices = eval_indices\n","    predictions, true_labels, sentence_ids = get_model_predictions(model, eval_dataloader)\n","    pred_sentences, pred_bert_examples = eval_sentences, eval_bert_examples\n","\n","  merged_predicted_spans = []\n","  # TODO sorting of spans???? may not be in order??\n","  for ii, _ in enumerate(predictions):\n","    get_span_prediction(predictions[ii], sentence_ids[ii], pred_sentences, pred_bert_examples)\n","  for span in predicted_spans:\n","    merged_predicted_spans.append(merge_spans(span))\n","  if mode == \"test\":\n","    return merged_predicted_spans \n","  if not os.path.isdir(\"predictions\"):\n","    os.mkdir(\"predictions\")\n","  copyfile(\"gdrive/My Drive/propaganda_detection/tools/task-SI_scorer.py\", \"predictions/task-SI_scorer.py\")\n","  with open(\"predictions/predictions.tsv\", 'w') as fp:\n","    for index in indices:\n","      filename = \"article\" + article_ids[index] + \".task1-SI.labels\"\n","      copyfile(os.path.join(data_dir, \"train-labels-task1-span-identification/\" + filename), \"predictions/\" + filename)\n","      for ii in merged_predicted_spans[index]:\n","        fp.write(article_ids[index] + \"\\t\" + str(ii[0]) + \"\\t\" + str(ii[1]) + \"\\n\")\n","\n","  !python3 predictions/task-SI_scorer.py -s predictions/predictions.tsv -r predictions/ -m\n","\n","  for index in indices:\n","    filename = \"article\" + article_ids[index] + \".task1-SI.labels\"\n","    os.remove(\"predictions/\" + filename)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"4b5d48a4-9bf5-4270-e918-0a0e32254cf3","executionInfo":{"status":"ok","timestamp":1586723206616,"user_tz":-330,"elapsed":4744,"user":{"displayName":"Paramansh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFUNSFhHphbpc_SffpUNDNLqiLPYS3aiygkhnRTw=s64","userId":"05094200950482431055"}},"id":"mf93bvb3gOf3","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["from transformers import DistilBertTokenizer\n","\n","articles, article_ids = read_articles('train-articles')\n","spans = read_spans()\n","TAGGING_SCHEME = \"PN\" # Positive Negative\n","# TAGGING_SCHEME = \"BIOE\"\n","NUM_ARTICLES = len(articles)\n","NUM_ARTICLES = 30\n","articles = articles[0:NUM_ARTICLES]\n","spans = spans[0:NUM_ARTICLES]\n","BATCH_SIZE=8\n","np.random.seed(245)\n","indices = np.arange(NUM_ARTICLES)\n","np.random.shuffle(indices)\n","train_indices = indices[:int(0.9 * NUM_ARTICLES)]\n","eval_indices = indices[int(0.9 * NUM_ARTICLES):]\n","\n","bert_model_class = 'bert-base-uncased'\n","# bert_model_class = \"bert-large-uncased-whole-word-masking\"\n","# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', lower_case=True)\n","# tokenizer = BertTokenizer.from_pretrained(bert_model_class, lower_case=True)\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","\n","train_dataloader, train_sentences, train_bert_examples = get_data(articles, spans, train_indices)\n","eval_dataloader, eval_sentences, eval_bert_examples = get_data(articles, spans, eval_indices)\n"],"execution_count":26,"outputs":[{"output_type":"stream","text":["988\n","106\n","171\n","53\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"auvkz5B7tIjp","colab_type":"code","outputId":"729d434c-ea02-4f83-9034-f392933541bd","executionInfo":{"status":"ok","timestamp":1586723394896,"user_tz":-330,"elapsed":191910,"user":{"displayName":"Paramansh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFUNSFhHphbpc_SffpUNDNLqiLPYS3aiygkhnRTw=s64","userId":"05094200950482431055"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# from transformers import BertForTokenClassification\n","\n","num_labels = 2 + int(TAGGING_SCHEME == \"BIO\") + 2 * int(TAGGING_SCHEME == \"BIOE\")\n","model = CustomBertForTokenClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)\n","model.cuda()\n","\n","from torch.optim import Adam\n","FULL_FINETUNING = True \n","if FULL_FINETUNING:\n","  param_optimizer = list(model.named_parameters())\n","  no_decay = ['bias', 'gamma', 'beta']\n","  optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","      'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","      'weight_decay_rate': 0.0}\n","  ]\n","else:\n","  param_optimizer = list(model.classifier.named_parameters()) \n","  optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n","optimizer = Adam(optimizer_grouped_parameters, lr=3e-6) # lr 3e-5\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","train(model, train_dataloader, eval_dataloader, epochs=6, save_model=(NUM_ARTICLES >= 150))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["\rEpoch:   0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train loss: 0.351732685249449\n","2020-04-12 20:27:09,262 - INFO - Checking user submitted file\n","2020-04-12 20:27:09,267 - INFO - Scoring the submission with precision and recall method\n","2020-04-12 20:27:09,267 - INFO - Precision=0.000000/0=0.000000\tRecall=0.000000/227=0.000000\n","2020-04-12 20:27:09,267 - INFO - F1=0.000000\n","Validation loss: 0.21459426006979562\n","2020-04-12 20:27:14,840 - INFO - Checking user submitted file\n","2020-04-12 20:27:14,841 - INFO - Scoring the submission with precision and recall method\n","2020-04-12 20:27:14,841 - INFO - Precision=0.000000/0=0.000000\tRecall=0.000000/34=0.000000\n","2020-04-12 20:27:14,842 - INFO - F1=0.000000\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  17%|█▋        | 1/6 [00:30<02:31, 30.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["Train loss: 0.30729312141756376\n","2020-04-12 20:27:39,784 - INFO - Checking user submitted file\n","2020-04-12 20:27:39,790 - INFO - Scoring the submission with precision and recall method\n","2020-04-12 20:27:39,791 - INFO - Precision=3.000000/3=1.000000\tRecall=0.570238/227=0.002512\n","2020-04-12 20:27:39,791 - INFO - F1=0.005012\n","Validation loss: 0.2032794359732758\n","2020-04-12 20:27:45,472 - INFO - Checking user submitted file\n","2020-04-12 20:27:45,473 - INFO - Scoring the submission with precision and recall method\n","2020-04-12 20:27:45,473 - INFO - Precision=0.000000/0=0.000000\tRecall=0.000000/34=0.000000\n","2020-04-12 20:27:45,473 - INFO - F1=0.000000\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  33%|███▎      | 2/6 [01:01<02:01, 30.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["Train loss: 0.26182244942455946\n","2020-04-12 20:28:10,401 - INFO - Checking user submitted file\n","2020-04-12 20:28:10,407 - INFO - Scoring the submission with precision and recall method\n","2020-04-12 20:28:10,424 - INFO - Precision=79.084017/95=0.832463\tRecall=18.997473/227=0.083689\n","2020-04-12 20:28:10,424 - INFO - F1=0.152089\n","Validation loss: 0.2415089719632471\n","2020-04-12 20:28:15,855 - INFO - Checking user submitted file\n","2020-04-12 20:28:15,856 - INFO - Scoring the submission with precision and recall method\n","2020-04-12 20:28:15,856 - INFO - Precision=0.000000/0=0.000000\tRecall=0.000000/34=0.000000\n","2020-04-12 20:28:15,856 - INFO - F1=0.000000\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  50%|█████     | 3/6 [01:31<01:31, 30.42s/it]"],"name":"stderr"},{"output_type":"stream","text":["Train loss: 0.2061470644647113\n","2020-04-12 20:28:40,968 - INFO - Checking user submitted file\n","2020-04-12 20:28:40,974 - INFO - Scoring the submission with precision and recall method\n","2020-04-12 20:28:41,020 - INFO - Precision=242.730880/275=0.882658\tRecall=66.707874/227=0.293867\n","2020-04-12 20:28:41,020 - INFO - F1=0.440933\n","Validation loss: 0.24836194788275118\n","2020-04-12 20:28:47,278 - INFO - Checking user submitted file\n","2020-04-12 20:28:47,279 - INFO - Scoring the submission with precision and recall method\n","2020-04-12 20:28:47,280 - INFO - Precision=0.000000/7=0.000000\tRecall=0.000000/34=0.000000\n","2020-04-12 20:28:47,280 - INFO - F1=0.000000\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  67%|██████▋   | 4/6 [02:03<01:01, 30.86s/it]"],"name":"stderr"},{"output_type":"stream","text":["Train loss: 0.16836300136369134\n","2020-04-12 20:29:12,533 - INFO - Checking user submitted file\n","2020-04-12 20:29:12,539 - INFO - Scoring the submission with precision and recall method\n","2020-04-12 20:29:12,550 - INFO - Precision=38.708602/41=0.944112\tRecall=9.285557/227=0.040906\n","2020-04-12 20:29:12,550 - INFO - F1=0.078414\n","Validation loss: 0.31536673920610075\n","2020-04-12 20:29:18,189 - INFO - Checking user submitted file\n","2020-04-12 20:29:18,190 - INFO - Scoring the submission with precision and recall method\n","2020-04-12 20:29:18,190 - INFO - Precision=0.000000/0=0.000000\tRecall=0.000000/34=0.000000\n","2020-04-12 20:29:18,191 - INFO - F1=0.000000\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  83%|████████▎ | 5/6 [02:33<00:30, 30.61s/it]"],"name":"stderr"},{"output_type":"stream","text":["Train loss: 0.14685817019788724\n","2020-04-12 20:29:44,006 - INFO - Checking user submitted file\n","2020-04-12 20:29:44,012 - INFO - Scoring the submission with precision and recall method\n","2020-04-12 20:29:44,038 - INFO - Precision=153.943406/163=0.944438\tRecall=27.854728/227=0.122708\n","2020-04-12 20:29:44,039 - INFO - F1=0.217196\n","Validation loss: 0.37780955646568065\n","2020-04-12 20:29:50,441 - INFO - Checking user submitted file\n","2020-04-12 20:29:50,442 - INFO - Scoring the submission with precision and recall method\n","2020-04-12 20:29:50,443 - INFO - Precision=0.000000/1=0.000000\tRecall=0.000000/34=0.000000\n","2020-04-12 20:29:50,443 - INFO - F1=0.000000\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch: 100%|██████████| 6/6 [03:06<00:00, 31.06s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"671ukmNyZohd","colab_type":"code","outputId":"9fdbab0f-2aef-44ce-c19b-d5c644d76d5d","executionInfo":{"status":"ok","timestamp":1586722972998,"user_tz":-330,"elapsed":30309,"user":{"displayName":"Paramansh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFUNSFhHphbpc_SffpUNDNLqiLPYS3aiygkhnRTw=s64","userId":"05094200950482431055"}},"colab":{"base_uri":"https://localhost:8080/","height":408}},"source":["train(model, train_dataloader, eval_dataloader, epochs=2, save_model=(NUM_ARTICLES >= 150))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["\rEpoch:   0%|          | 0/2 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train loss: 0.17941840960812636\n","2020-04-12 20:22:31,153 - INFO - Checking user submitted file\n","2020-04-12 20:22:31,156 - INFO - Scoring the submission with precision and recall method\n","2020-04-12 20:22:31,178 - INFO - Precision=77.250554/181=0.426799\tRecall=52.633456/66=0.797477\n","2020-04-12 20:22:31,178 - INFO - F1=0.556022\n","Validation loss: 0.3921118378639221\n","2020-04-12 20:22:34,975 - INFO - Checking user submitted file\n","2020-04-12 20:22:34,975 - INFO - Scoring the submission with precision and recall method\n","2020-04-12 20:22:34,975 - INFO - Precision=0.000000/3=0.000000\tRecall=0.000000/1=0.000000\n","2020-04-12 20:22:34,975 - INFO - F1=0.000000\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  50%|█████     | 1/2 [00:13<00:13, 13.79s/it]"],"name":"stderr"},{"output_type":"stream","text":["Train loss: 0.1594885269532273\n","2020-04-12 20:22:44,883 - INFO - Checking user submitted file\n","2020-04-12 20:22:44,888 - INFO - Scoring the submission with precision and recall method\n","2020-04-12 20:22:44,927 - INFO - Precision=43.971136/274=0.160479\tRecall=64.984852/66=0.984619\n","2020-04-12 20:22:44,927 - INFO - F1=0.275977\n","Validation loss: 0.44500982761383057\n","2020-04-12 20:22:48,810 - INFO - Checking user submitted file\n","2020-04-12 20:22:48,811 - INFO - Scoring the submission with precision and recall method\n","2020-04-12 20:22:48,811 - INFO - Precision=0.000000/7=0.000000\tRecall=0.000000/1=0.000000\n","2020-04-12 20:22:48,811 - INFO - F1=0.000000\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch: 100%|██████████| 2/2 [00:27<00:00, 13.94s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"AopDosLFYuSl","colab_type":"code","colab":{}},"source":["torch.save(model.state_dict(), os.path.join(model_dir, 'span_state_dict.pt'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GUUmSkoTrbvE","colab_type":"code","colab":{}},"source":[" Ntorch.save(model, os.path.join(model_dir, 'model_bioe_weighted_deep2.pt'))\n","# model = torch.load(os.path.join(model_dir, 'model_2020-02-28 22:05:59.981128.pt'))\n","# model.cuda()\n","\n","# WEIGHTS = torch.tensor([1.0, 10.0, 10.0, 10.0]).cuda()\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# from torch.optim import Adam\n","# FULL_FINETUNING = True \n","# if FULL_FINETUNING:\n","#   param_optimizer = list(model.named_parameters())\n","#   no_decay = ['bias', 'gamma', 'beta']\n","#   optimizer_grouped_parameters = [\n","#     {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","#       'weight_decay_rate': 0.01},\n","#     {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","#       'weight_decay_rate': 0.0}\n","#   ]\n","# else:\n","#   param_optimizer = list(model.classifier.named_parameters()) \n","#   optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n","# optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)\n","# get_score(model, mode='eval')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wPBCR48PGVu-","colab_type":"code","outputId":"ccaa7644-45d3-4da7-d070-1a7edefa7c26","executionInfo":{"status":"error","timestamp":1583005094320,"user_tz":-330,"elapsed":9668,"user":{"displayName":"Paramansh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mANS3lCUfabnCwNFz8A_Mb-FC_uqCl9Y4r-zhTcvA=s64","userId":"05094200950482431055"}},"colab":{"base_uri":"https://localhost:8080/","height":369}},"source":["train(model, train_dataloader, eval_dataloader, epochs=10, save_model=(NUM_ARTICLES >= 150))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","\n","Epoch:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-3304ed51fc54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_ARTICLES\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-17-bc80f2998023>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, eval_dataloader, epochs, save_model)\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m       \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mnb_tr_examples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mb_input_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"AUmj8j4M878b","colab_type":"code","outputId":"24538c42-996c-413a-f2a4-66cf5f899e76","executionInfo":{"status":"ok","timestamp":1582703047103,"user_tz":-330,"elapsed":64067,"user":{"displayName":"Paramansh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mANS3lCUfabnCwNFz8A_Mb-FC_uqCl9Y4r-zhTcvA=s64","userId":"05094200950482431055"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = torch.load(os.path.join(model_dir, 'model_2020-02-25 20:05:27.163346.pt'))\n","# get_score(model, mode=\"train\")\n","# print()\n","get_score(model, mode=\"eval\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-02-26 07:44:03,409 - INFO - Checking user submitted file\n","2020-02-26 07:44:03,425 - INFO - Scoring the submission with precision and recall method\n","2020-02-26 07:44:03,598 - INFO - Precision=228.062968/434=0.525491\tRecall=245.284300/607=0.404093\n","2020-02-26 07:44:03,599 - INFO - F1=0.456865\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AT6dQaUZGUww","colab_type":"code","outputId":"7f1490d5-13f7-4cbe-f97d-e73e767c69b3","executionInfo":{"status":"ok","timestamp":1583318054138,"user_tz":-330,"elapsed":2602,"user":{"displayName":"Paramansh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFUNSFhHphbpc_SffpUNDNLqiLPYS3aiygkhnRTw=s64","userId":"05094200950482431055"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["text = \"hello https://google.co.in bye bye\"\n","url_pattern = r'((http|ftp|https):\\/\\/)?[\\w\\-_]+(\\.[\\w\\-_]+)+([\\w\\-\\.,@?^=%&amp;:/~\\+#]*[\\w\\-\\@?^=%&amp;/~\\+#])?'\n","text = re.sub(url_pattern, ' ', text)\n","print(text)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["hello   bye bye\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gV5wHUoGC4xV","colab_type":"code","colab":{}},"source":["import json\n","import re\n","with open(os.path.join(home_dir, 'trump_tweets.json')) as f:\n","  tweet_json = json.load(f)\n","trump_tweets = []\n","for tweet in tweet_json:\n","  tweet_text = tweet['text']\n","  if len(tweet_text) > 50 and tweet_text[0:2] != \"RT\":\n","    url_pattern = r'((http|ftp|https):\\/\\/)?[\\w\\-_]+(\\.[\\w\\-_]+)+([\\w\\-\\.,@?^=%&amp;:/~\\+#]*[\\w\\-\\@?^=%&amp;/~\\+#])?'\n","    tweet_text = re.sub(url_pattern, ' ', tweet_text)\n","    trump_tweets.append(tweet_text)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"3dc26914-2684-46ed-aa3c-0219c583f531","executionInfo":{"status":"ok","timestamp":1583326855623,"user_tz":-330,"elapsed":6913,"user":{"displayName":"Paramansh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFUNSFhHphbpc_SffpUNDNLqiLPYS3aiygkhnRTw=s64","userId":"05094200950482431055"}},"id":"yk4vK9brE9Ui","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","test_articles = [\"Mini Mike, don’t lick your dirty fingers. Both unsanitary and dangerous to others and yourself!\"]\n","num_tweets = 100\n","test_articles = trump_tweets[0:num_tweets]\n","ind = 0\n","# model = torch.load(os.path.join(model_dir, 'model_370_44_bioe.pt'))\n","\n","# test_articles = [articles[ind]]\n","test_spans = [[]] * len(test_articles)\n","\n","test_dataloader, test_sentences, test_bert_examples = get_data(test_articles, test_spans, indices=np.arange(len(test_articles)))\n","sps = get_score(model, mode=\"test\")\n","for i in range(num_tweets):\n","  print(test_articles[i])\n","  print('Detected span: ')\n","  print_spans(test_articles[i], sps[i])\n","  print('--' * 50)\n","# print_spans(articles[ind], spans[ind])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["101\n","50\n","The only people in favor of Mini Mike continuing with his hapless campaign are me and his political consultants, who are getting richer and richer by the day!\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n",".@FoxNews is working hard pushing the Radical Left, Do Nothing Democrats. They want to be, unlike their competitors, @CNN &amp; MSDNC (Comcast), Fair &amp; Balanced. When will they ever learn. The Radical Left never even gave @FoxNews permission to partake in their low rated debates!\n","Detected span: \n","Democrats. They want to be, unlike their competitors, @CNN &amp; MSDNC (Comcast), Fair &amp; Balanced. When will they ever learn. The Radical Left never even gave @FoxNews permission to partake in their low rated debates\n","\n","----------------------------------------------------------------------------------------------------\n","....competitive disadvantage. We should be leading, not following!\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","As usual, Jay Powell and the Federal Reserve are slow to act. Germany and others are pumping money into their economies. Other Central Banks are much more aggressive. The  . should have, for all of the right reasons, the lowest Rate. We don’t, putting us at a.....\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","Jack Welch, former Chairman and CEO of GE, a business legend, has died. There was no corporate leader like “neutron” Jack. He was my friend and supporter. We made wonderful deals together. He will never be forgotten. My warmest sympathies to his wonderful wife &amp; family!\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","I was criticized by the Democrats when I closed the Country down to China many weeks ahead of what almost everyone recommended. Saved many lives. Dems were working the Impeachment Hoax. They didn’t have a clue! Now they are fear mongering. Be calm &amp; vigilant!\n","Detected span: \n","Dems\n","\n","----------------------------------------------------------------------------------------------------\n","“Ever since (Mini Mike) Bloomberg’s bad debate performances, his support has dropped.” @abcnews  Dropped a lot. Only his highly paid consultants, who are laughing all the way to the bank, still support him...And by the way, he did not poll well as mayor in handling crisis!\n","Detected span: \n","(Mini Mike)\n","are laughing all the way to the\n","the way,\n","did not\n","\n","----------------------------------------------------------------------------------------------------\n","I am meeting with the major pharmaceutical companies today at the White House about progress on a vaccine and cure. Progress being made!\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","“The Democrat Party is a field of lightweights in complete disarray.” @kayleighmcenany @JudgeJeanine\n","Detected span: \n","complete disarray.”\n","\n","----------------------------------------------------------------------------------------------------\n","Gallup Poll numbers on the handling of this situation are outstanding, the best. Thank you!  \n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","Watch Mark Levin interview of Charlie Kirk tonight at 11:00  . on @FoxNews. Amazing!!!  And, while you’re at it, go get Charlie’s new book, “The MAGA Doctrine: The Only Ideas That Will Win the Future”...This is a really GREAT book. Support Charlie Kirk!\n","Detected span: \n","MAGA Doctrine:\n","\n","----------------------------------------------------------------------------------------------------\n","Sleepy Eyes Chuck Todd is not at the top of his game! Thank you.  \n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","Sleepy Joe Biden also said that guns killed 150 million Americans last year, wants to win Georgia on Super Tuesday (not up), and got his speaking location wrong again!  \n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","The Black community brilliantly turned their backs on Mini Mike because they know he is a pandering phony who never did right by them!  \n","Detected span: \n","Black community\n","their backs on\n","pandering phony who never did right by them!\n","\n","----------------------------------------------------------------------------------------------------\n","Mini Mike Bloomberg didn’t bring NYC back, as he said in his fake ad. It was @RudyGiuliani who brought NYC back and who also, with his endorsement, got Mini Mike elected (with barely a thank you). A boring mayor who the people couldn’t stand!\n","Detected span: \n","A boring mayor who the people couldn’t stand\n","\n","----------------------------------------------------------------------------------------------------\n","Pete Buttigieg is OUT. All of his SuperTuesday votes will go to Sleepy Joe Biden. Great timing. This is the REAL beginning of the Dems taking Bernie out of play - NO NOMINATION, AGAIN!\n","Detected span: \n","Dems\n","\n","----------------------------------------------------------------------------------------------------\n","People are disgusted and embarrassed by the Fake News Media, as headed by the @nytimes, @washingtonpost, @comcast &amp; MSDNC, @ABC, @CBSNews and more. They no longer believe what they see and read, and for good reason. Fake News is, indeed, THE ENEMY OF THE PEOPLE!\n","Detected span: \n","disgusted and embarrassed\n","They no longer believe what they see and read, and for good reason. Fake News is, indeed, THE ENEMY OF THE PEOPLE\n","\n","----------------------------------------------------------------------------------------------------\n","“Who better than @RepRatcliffe, who got to the bottom of the FISAGATE &amp; RUSSIAGATE HOAX. It makes a lot of sense to put John Ratcliffe in there (DNI).The Senate should quickly approve him. @DevinNunes @MariaBartiromo  John will do a great job for the American people!\n","Detected span: \n","job\n","American people\n","\n","----------------------------------------------------------------------------------------------------\n","A Poll in today’s New York Post says that 77% of “ . adults have confidence in their government’s ability to handle the Coronavirus (Number One), compared to other health threats.” 64% for Zika, 58% for Ebola. Others way down on list. Our professionals are doing a great job!\n","Detected span: \n","Our professionals are doing a great job\n","\n","----------------------------------------------------------------------------------------------------\n","The food is GREAT at Sammy’s Mexican Grill in Phoenix, Arizona. Congratulations to Betty &amp; Jorge Rivas on doing such a wonderful job. I will try hard to stop by the next time I am in Phoenix. Support Sammy’s! @foxandfriends\n","Detected span: \n","wonderful\n","\n","----------------------------------------------------------------------------------------------------\n","Coronavirus: In addition to screening travelers “prior to boarding” from certain designated high risk countries, or areas within those countries, they will also be screened when they arrive in America. Thank you! @VP @SecAzar @CDCgov @CDCDirector\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n",".....a very dark and lonely path! Your reputation will never be the same!\n","Detected span: \n",".....a very dark and lonely path! Your reputation will never be the same\n","\n","----------------------------------------------------------------------------------------------------\n","Mini Mike Bloomberg’s consultants and so-called “advisors”(how did that advice work out? Don’t ask!), are on the “gravy train” and all making a fortune for themselves pushing Mini hard, when they knew he never had what it takes. Don’t pay them anymore Mike, they led you down....\n","Detected span: \n","Don’t ask!),\n","“gravy train”\n","\n","----------------------------------------------------------------------------------------------------\n","I would find it hard to believe that failed presidential candidates Tom Steyer, or Mini Mike Bloombeg, would contribute to the Democrat Party, even against me, after the way they have been treated - laughed at &amp; mocked. The real politicians ate them up and spit them out!\n","Detected span: \n","have been treated - laughed at &amp;\n","The real politicians ate them up and spit them out\n","\n","----------------------------------------------------------------------------------------------------\n","Tom Steyer who, other than Mini Mike Bloomberg, spent more dollars for NOTHING than any candidate in history, quit the race today proclaiming how thrilled he was to be a part of the the Democrat Clown Show. Go away Tom and save whatever little money you have left!\n","Detected span: \n","dollars for\n","than any candidate in history,\n","the Democrat Clown Show. Go away Tom and save whatever little money you have left\n","\n","----------------------------------------------------------------------------------------------------\n","Democrats are working hard to destroy the name and reputation of Crazy Bernie Sanders, and take the nomination away from him!\n","Detected span: \n","Crazy\n","Sanders,\n","\n","----------------------------------------------------------------------------------------------------\n","Sleepy Joe Biden’s victory in the South Carolina Democrat Primary should be the end of Mini Mike Bloomberg’s Joke of a campaign. After the worst debate performance in the history of presidential debates,  Mini Mike now has Biden split up his very few voters, taking many away!\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","Dana, you are the real deal!  \n","Detected span: \n","real deal!\n","\n","----------------------------------------------------------------------------------------------------\n","I will be having a 1:30  . Press Conference at the White House to discuss the latest CoronaVirus developments. Thank you!\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","South Carolina was GREAT. A BIG &amp; REALLY ENTHUSIASTIC CROWD!\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","A so-called reporter named @JohnJHarwood, who bombed so badly in the 2016 Presidential Debates that I thought he was going to be immediately fired (a Mini Mike type performance), is now with Fake News @CNN. A total loser!\n","Detected span: \n","badly\n","A total loser\n","\n","----------------------------------------------------------------------------------------------------\n","I hope we can get Admiral @RonnyJackson4TX of Texas, who served our Country so well, into the runoff election in #TX13! Ronny is strong on Crime and Borders, GREAT for our Military and Vets, and will protect your #2A. Get out and vote for Ronny on Tuesday, March 3rd!\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","Thank you to all of the incredible Law Enforcement Officers in South Carolina tonight. We love you!  \n","Detected span: \n","Law Enforcement\n","\n","----------------------------------------------------------------------------------------------------\n","It was my great honor to be back in South Carolina tonight, with thousands of hardworking American Patriots who believe in Faith, Family, God and Country. Thank you for a beautiful evening! #KAG2020  \n","Detected span: \n","hardworking\n","\n","----------------------------------------------------------------------------------------------------\n","I am pleased to announce the nomination of @RepRatcliffe (Congressman John Ratcliffe) to be Director of National Intelligence (DNI). Would have completed process earlier, but John wanted to wait until after IG Report was finished. John is an outstanding man of great talent!\n","Detected span: \n","outstanding man of great talent\n","\n","----------------------------------------------------------------------------------------------------\n","On my way to the Great State of South Carolina. See everyone soon! #MAGA #KAG  \n","Detected span: \n","#MAGA\n","\n","----------------------------------------------------------------------------------------------------\n","Nobody fights harder for Montana than @SteveDaines. Steve is a close friend of mine, a STRONG Conservative, and a tremendous supporter of our #MAGA Agenda. He is strong on Crime &amp; Borders, GREAT for our Military &amp; Vets, &amp; will protect your #2A. Steve has my Complete Endorsement!\n","Detected span: \n","harder\n","\n","----------------------------------------------------------------------------------------------------\n","The Dems are working hard to take the prized nomination away from Bernie. Back room politics, which Bernie is not very good at. His people will not let it happen again!\n","Detected span: \n","Dems\n","His people will not let it happen again\n","\n","----------------------------------------------------------------------------------------------------\n","Mini Mike is getting slammed. His debates were, perhaps, the worst in presidential debating history. A total phony who disavowed “Stop &amp; Frisk” after swearing by it for years, and even recently. He horribly overused it, &amp; then dropped when running as a Dem. A total phony!\n","Detected span: \n","A total phony\n","&amp;\n","A total phony\n","\n","----------------------------------------------------------------------------------------------------\n","We strongly stand with Terrence!  \n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","“You go around Pennsylvania and you see Trump signs everywhere. The Donald Trump situation is bigger than the Reagan Revolution. Donald Trump has inspired us.” @RjHarris15  WHP580\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","Worst Polls, just like in 2016 when they were so far off the mark, are the @FoxNews Polls. Why doesn’t Fox finally get a competent Polling Company?\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","To the people of South Carolina, Tom Steyer is a joke, laughed at by everyone, a total incompetent. He made money in coal, now he “hates” coal. Did you see him fawning over Crazy Bernie? Has no chance, a loser for South Carolina, doesn’t deserve your vote!\n","Detected span: \n","total incompetent.\n","Did you see him fawning over Crazy Bernie?\n","no chance, a loser for South Carolina, doesn’t deserve your vote\n","\n","----------------------------------------------------------------------------------------------------\n","Will be in the Great State of South Carolina tonight, 7:00  ., for a really BIG Rally. Best place to be is a Trump Rally. See you later!\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","“Federal Court Deals Major Blow To Sanctuary Cities.” @FoxNews  In other words, there will be no more Federal Tax Dollars to States &amp; Cities that will not cooperate with Federal Law Enforcement (ICE). This is BIG NEWS! Funds will be cut off immediately. MAKE AMERICA GREAT AGAIN!\n","Detected span: \n","is BIG NEWS!\n","MAKE AMERICA GREAT AGAIN\n","\n","----------------------------------------------------------------------------------------------------\n","The Do Nothing Democrats were busy wasting time on the Immigration Hoax, &amp; anything else they could do to make the Republican Party look bad, while I was busy calling early BORDER &amp; FLIGHT closings, putting us way ahead in our battle with Coronavirus. Dems called it VERY wrong!\n","Detected span: \n","Dems\n","\n","----------------------------------------------------------------------------------------------------\n","So, the Coronavirus, which started in China and spread to various countries throughout the world, but very slowly in the  . because President Trump closed our border, and ended flights, VERY EARLY, is now being blamed, by the Do Nothing Democrats, to be the fault of “Trump”.\n","Detected span: \n","Do\n","\n","----------------------------------------------------------------------------------------------------\n","“Diagnosis positive: @CNN is infected with Trump Derangement Syndrome. I’m calling out CNN for irresponsibly politicizing what should be a unifying battle against a virus that doesn’t choose sides.” @trish_regan @FoxNews  Like I say, they are Fake News!\n","Detected span: \n","Trump Derangement Syndrome.\n","\n","----------------------------------------------------------------------------------------------------\n","Word is that Mini Mike Bloomberg performed so poorly in the two debates, that he is thinking about dropping out of the Democrat Primary. The fact is, he was not true to himself, and the public was able to quickly figure him out. Not a good experience for Mini Mike!\n","Detected span: \n","Mini\n","Mini Mike\n","\n","----------------------------------------------------------------------------------------------------\n","Congratulations and thank you to our great Vice President &amp; all of the many professionals doing such a fine job at CDC &amp; all other agencies on the Coronavirus situation. Only a very small number in  ., &amp; China numbers look to be going down. All countries working well together!\n","Detected span: \n","a fine\n","\n","----------------------------------------------------------------------------------------------------\n","Do Nothing Democrats were busy wasting their time on the Impeachment Hoax, &amp; anything they could do to make the Republican Party look bad, while I was busy calling early boarder &amp; flight closings, putting us way ahead in our battle with the Coronavirus. Dems called it very wrong!\n","Detected span: \n","Dems\n","\n","----------------------------------------------------------------------------------------------------\n","“Anti-Trump Network @CNN doing whatever it can to stoke a national Coronavirus panic. The far left Network pretty much ignoring anyone who they interview who doesn’t blame President Trump.” @trish_regan @FoxNews Media refuses to discuss the great job our professionals are doing!\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n",".@RepKevinBrady (R) of Texas-08 loves Texas &amp; our Country. He has been a GREAT Congressman &amp; supporter of #MAGA. Strong on Crime, Border, Military, Vets and your 2A, he is the best Tax Cutter in  . Kevin has my Complete &amp; Total Endorsement. Vote on March 3rd. Thank you!\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","Nancy has allowed her District to go down more than any other in the USA! Hardly even recognizable.  \n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","My two great friends. Proud of you both!  \n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","Eric, I can live with that!  \n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","Big Rally in the Great State of South Carolina on Friday. See you there!\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","“Every poll you look at shows that Black support for President Trump is growing.” @RealCandaceO @MariaBartiromo\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","Big Story, Big Win - Except in the Fake News, which won’t cover it!  \n","Detected span: \n","Win\n","\n","----------------------------------------------------------------------------------------------------\n","....during a debate). Pocahontas was mean, &amp; undisciplined, mostly aiming at Crazy Bernie and Mini Mike. They don’t know how to handle her, but I know she is a “chocker”. Steyer was a disaster who, along with Mini, are setting records in $’s per vote. Just give me an opponent!\n","Detected span: \n","mean,\n","Crazy Bernie\n","Mini Mike.\n","a “chocker”.\n","disaster\n","\n","----------------------------------------------------------------------------------------------------\n","Crazy, chaotic Democrat Debate last night. Fake News said Biden did well, even though he said half of our population was shot to death. Would be OVER for most. Mini Mike was weak and unsteady, but helped greatly by his many commercials (which are not supposed to be allowed....\n","Detected span: \n","Crazy,\n","to death.\n","be OVER for most.\n","\n","----------------------------------------------------------------------------------------------------\n","I will be having a News Conference at the White House, on this subject, today at 6:00  . CDC representatives, and others, will be there. Thank you!\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","Low Ratings Fake News MSDNC (Comcast) &amp; @CNN are doing everything possible to make the Caronavirus look as bad as possible, including panicking markets, if possible. Likewise their incompetent Do Nothing Democrat comrades are all talk, no action. USA in great shape! @CDCgov.....\n","Detected span: \n","incompetent Do Nothing Democrat comrades\n","USA in great shape!\n","\n","----------------------------------------------------------------------------------------------------\n","Just landed. India was great, trip very successful. Heading to the White House. Meetings and calls scheduled today. @CDCgov, @SecAzar and all doing a great job with respect to Coronavirus! Briefing this afternoon.\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","“ . acted on the Coronavirus very, very quickly.” Gordon Chang  @IngrahamAngle\n","Detected span: \n","very, very quickly.”\n","\n","----------------------------------------------------------------------------------------------------\n","52% in the new Rasmussen Poll. 95% Approval Rating in the Republican Party. Thank you!\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","....Democrats talking point is that we are doing badly. If the virus disappeared tomorrow, they would say we did a really poor, and even incompetent, job. Not fair, but it is what it is. So far, by the way, we have not had one death. Let’s keep it that way!\n","Detected span: \n","badly.\n","did a really poor, and even incompetent, job.\n","\n","----------------------------------------------------------------------------------------------------\n","CDC and my Administration are doing a GREAT job of handling Coronavirus, including the very early closing of our borders to certain areas of the world. It was opposed by the Dems, “too soon”, but turned out to be the correct decision. No matter how well we do, however, the.....\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","That is because they cover your favorite President relatively well. @CNN &amp; MSDNC are dying in the ratings!  \n","Detected span: \n","dying in the ratings!\n","\n","----------------------------------------------------------------------------------------------------\n","True, but we are getting it all done!  \n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","A total miscarriage of justice!  \n","Detected span: \n","A total miscarriage of justice!\n","\n","----------------------------------------------------------------------------------------------------\n","There has rarely been a juror so tainted as the forewoman in the Roger Stone case. Look at her background. She never revealed her hatred of “Trump” and Stone. She was totally biased, as is the judge. Roger wasn’t even working on my campaign. Miscarriage of justice. Sad to watch!\n","Detected span: \n","Miscarriage of justice.\n","\n","----------------------------------------------------------------------------------------------------\n","Cryin’ Chuck Schumer is complaining, for publicity purposes only, that I should be asking for more money than $  Billion to prepare for Coronavirus. If I asked for more he would say it is too much. He didn’t like my early travel closings. I was right. He is incompetent!\n","Detected span: \n","Cryin’\n","incompetent\n","\n","----------------------------------------------------------------------------------------------------\n","“Sotomayor accuses GOP appointed Justices  of being biased in favor of Trump.” @IngrahamAngle @FoxNews  This is a terrible thing to say. Trying to “shame” some into voting her way? She never criticized Justice Ginsberg when she called me a “faker”. Both should recuse themselves..\n","Detected span: \n","Trying to “shame” some into voting her way? She never criticized Justice Ginsberg when she called me a “faker”. Both should recuse themselves.\n","\n","----------------------------------------------------------------------------------------------------\n","....on all Trump, or Trump related, matters! While “elections have consequences”, I only ask for fairness, especially when it comes to decisions made by the United States Supreme Court!\n","Detected span: \n","I only ask for fairness, especially when it comes to decisions made by the United States Supreme Court\n","\n","----------------------------------------------------------------------------------------------------\n","..It has been a scam right from the beginning with the illegally started Mueller Report, FISA, the leaking, lying &amp; more. Schiff should not have access to Intelligence, he is a corrupt pol. “Amazing that they went to Bernie Sanders, but not to President Trump.” @marthamaccallum\n","Detected span: \n","a corrupt pol. “Amazing\n","\n","----------------------------------------------------------------------------------------------------\n","“ . Intelligence official overstated assessment of Russian efforts to help Trump.” @FoxNews @GreggJarrett They supposedly told Crazy Bernie that Russia was looking at him, not me. This is all a big scam between Intel and the Democrats. They want Bernie OUT, &amp; hate “Trump”.\n","Detected span: \n","Crazy Bernie\n","a big scam\n","\n","----------------------------------------------------------------------------------------------------\n","Great new book just out, “Taken for Granted, How Conservatives Can Win Back Americans That Liberalism Failed”, by Gianni Caldwell, a young winner! He will be at the Ronald Reagan Library, Simi Valley, California, on Thursday at 6 PM, PT. Check it out!\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","The Coronavirus is very much under control in the USA. We are in contact with everyone and all relevant countries. CDC &amp; World Health have been working hard and very smart. Stock Market starting to look very good to me!\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","Set up by Schiff’s lies &amp; leaks. Same with the Mueller Witch Hunt 3 years ago!  \n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","THANK YOU @NarendraModi!🇺🇸🇮🇳  \n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","मैं  इसी  लिए भारत आया हूँ, सद्भावना और प्रेम के साथ ताकि हम अपनी अभिलाषा  प्रतीक अपनी सांझेदारी और अविश्वसनीय  विस्तार  सकें l  \n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","Our two national constitutions both begin with the same three beautiful words: “We the people.” That means that in America and India alike, we honor, respect, trust, empower, and fight for the citizens we proudly serve! 🇺🇸🇮🇳  \n","Detected span: \n","Our\n","national constitutions\n","“We the people.”\n","means that in America and India alike, we honor, respect, trust, empower, and fight for the citizens we proudly serve! 🇺🇸🇮🇳\n","\n","----------------------------------------------------------------------------------------------------\n","अमेरिका और भारत अपने देशों को मजबूत बनाएँगे,  अपने लोगों को सम्पन्न बनाएँगे, बड़े सपने देखने वालों को और बड़ा बनाएँगे और अपना भविष्य पहले से कहीं अधिक उज्जवल बनाएँगे... और यह तो शुरुआत ही है।\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","प्रथम महिला और मैं इस देश के हर नागरिक को एक सन्देश देने के लिए दुनिया का 8000 मील का चक्कर लगा कर यहां आये हैं l अमेरिका भारत को  प्रेम करता है - अमेरिका भारत का सम्मान करता है - और \n","अमरीका के लोग हमेशा भारत के लोगों के सच्चे और निष्ठावान दोस्त रहेंगे l  \n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","हम भारत आने के लिए तत्पर हैं । हम रास्ते में हैँ, कुछ ही घंटों में हम सबसे मिलेंगे!\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","95% Approval Rating in the Republican Party, a Record. 218 Federal Judges, also a Record. 2 Supreme Court Justices. Thank you!\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","Crazy Bernie and the Democrats should see this. I have done far more for the African American community than any President. Secured funding for HBCUs, Criminal Justice Reform, Opportunity Zones, School Choice, Record Low Unemployment, and so much more. THE BEST IS YET TO COME!  \n","Detected span: \n","Crazy\n","THE BEST IS YET TO COME!\n","\n","----------------------------------------------------------------------------------------------------\n","Crazy Bernie and the Democrats should see this. I I have done more  \n","Detected span: \n","Crazy\n","\n","----------------------------------------------------------------------------------------------------\n","Jeff Van Drew is a Courageous Leader that left the Do Nothing Democrats to better serve the Great people of New Jersey. HAPPY BIRTHDAY @CongressmanJVD!\n","Detected span: \n","Courageous Leader\n","left the Do Nothing Democrats\n","Great people of New Jersey.\n","\n","----------------------------------------------------------------------------------------------------\n","Are any Democrat operatives, the DNC, or Crooked Hillary Clinton, blaming Russia, Russia, Russia for the Bernie Sanders win in Nevada. If so I suggest calling Bob Mueller &amp; the 13 Angry Democrats to do a new Mueller Report, Democrat Edition. Bob will get to the bottom of it!\n","Detected span: \n","Democrats\n","\n","----------------------------------------------------------------------------------------------------\n","Somebody please tell incompetent (thanks for my high poll numbers) &amp; corrupt politician Adam “Shifty” Schiff to stop leaking Classified information or, even worse, made up information, to the Fake News Media. Someday he will be caught, &amp; that will be a very unpleasant experience!\n","Detected span: \n","“Shifty”\n","experience\n","\n","----------------------------------------------------------------------------------------------------\n","Look forward to being with all of my friends and supporters @CPAC on Saturday, February 29th! #KAG2020  \n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","Departing for India with Melania!  \n","Detected span: \n","Melania!\n","\n","----------------------------------------------------------------------------------------------------\n","Just another Shifty Schiff leak. Isn’t there a law about this stuff?  \n","Detected span: \n","Shifty\n","\n","----------------------------------------------------------------------------------------------------\n","“The Kremlin is reportedly backing Bernie Sanders bid to win the White House.” Jon Scott  @FoxNews  Why didn’t somebody tell me this?\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","Looks like Crazy Bernie is doing well in the Great State of Nevada. Biden &amp; the rest look weak, &amp; no way Mini Mike can restart his campaign after the worst debate performance in the history of Presidential Debates. Congratulations Bernie, &amp; don’t let them take it away from you!\n","Detected span: \n","don’t let them take it away from you\n","\n","----------------------------------------------------------------------------------------------------\n","Look so forward to being with my great friends in INDIA!  \n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n","Democrats in the Great State of Nevada (Which, because of the Economy, Jobs, the Military &amp; Vets, I will win in November), be careful of Russia, Russia, Russia. According to Corrupt politician Adam “Shifty” Schiff, they are pushing for Crazy Bernie Sanders to win. Vote!\n","Detected span: \n","politician\n","“Shifty”\n","Crazy\n","Sanders\n","\n","----------------------------------------------------------------------------------------------------\n","“An investigation into NOTHING.” The wonderful @trish_regan on the Mueller Witch Hunt!\n","Detected span: \n","\n","----------------------------------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AVKzjMZOMoFV","colab_type":"code","outputId":"f3e2bbfa-392d-4592-a52c-1785241fc17e","executionInfo":{"status":"ok","timestamp":1583005650913,"user_tz":-330,"elapsed":33403,"user":{"displayName":"Paramansh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mANS3lCUfabnCwNFz8A_Mb-FC_uqCl9Y4r-zhTcvA=s64","userId":"05094200950482431055"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["ind = 32\n","model = torch.load(os.path.join(model_dir, 'model_370_44_bioe.pt'))\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","test_articles, test_article_ids = read_articles('test-articles')\n","# test_articles = [articles[ind]]\n","test_spans = [[]] * len(test_articles)\n","\n","test_dataloader, test_sentences, test_bert_examples = get_data(test_articles, test_spans, indices=np.arange(len(test_articles)))\n","sps = get_score(model, mode=\"test\")\n","# print_spans(articles[ind], sps[0])\n","# print('--' * 50)\n","# print_spans(articles[ind], spans[ind])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["3185\n","124\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gf_VICv6u5-q","colab_type":"code","colab":{}},"source":["from google.colab import files\n","with open('predictions/dev_predictions.txt', 'w') as fp:\n","  for index in range(len(test_articles)):\n","    for ii in sps[index]:\n","      fp.write(test_article_ids[index] + \"\\t\" + str(ii[0]) + \"\\t\" + str(ii[1]) + \"\\n\")\n","files.download('predictions/dev_predictions.txt')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9HK4sY9KENbV","colab_type":"code","colab":{}},"source":["# torch.save(model, os.path.join(model_dir, 'model_300_42.pt'))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-98Mlmdk4S7n","colab_type":"code","outputId":"f83df49f-8d34-4188-fff7-a7cb743f1dfd","executionInfo":{"status":"ok","timestamp":1580328283170,"user_tz":-330,"elapsed":1019,"user":{"displayName":"Paramansh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mANS3lCUfabnCwNFz8A_Mb-FC_uqCl9Y4r-zhTcvA=s64","userId":"05094200950482431055"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for index in eval_indices:\n","  print(\"article index:\",index)\n","  span = merged_predicted_spans[index]\n","  print_spans(articles[index], span)\n","  print()\n","  print_spans(articles[index], spans[index])\n","  print(\"--\" * 50)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["article index: 107\n","“sort of in a panic”\n","that someone might “break into his apartment” looking for it, like “that Watergate crap.”\n","it,”\n","black-owned businesses.\n","institutions\n","“spiritual advisor”\n","Reading Obama’s 1995 memoir, you might almost get the impression that after a prudent first term, during his second he might side with, I dunno, Black Lives Matter and encourage a wave of black rage and police retreat that drove up the death toll from murder by 20% in his last two years in office, an incremental death toll a little bigger than the U.S. combat death toll from the equally stupid Iraq War.\n","\n","\n","spiritual advisor\n","sort of in a panic\n","black\n","shaking down white institutions\n","Reading Obama’s 1995 memoir, you might almost get the impression that after a prudent first term, during his second he might side with, I dunno, Black Lives Matter and encourage a wave of black rage and police retreat that drove up the death toll from murder by 20% in his last two years in office, an incremental death toll a little bigger than the U.S. combat death toll from the equally stupid Iraq War\n","was afraid that someone might “break into his apartment” looking for it\n","crap\n","\n","----------------------------------------------------------------------------------------------------\n","article index: 123\n","Hitler-Loving Anti-Semite\n","The media is very interested in racism.\n","“outstanding human being”\n","white people “deserve to die”\n","Adolf Hitler\n","a “very great man.”\n","him as an outstanding human being who commands a following of individuals who are learned and articulate and he plays a big role in the lives of thousands and thousands and thousands and thousands of people,”\n","many people in politics have a history of inflammatory comments.\n","Farrakhan had praised Hitler and declared that the Jews, \"can't say 'Never Again' to God, because when he puts you in the ovens, you're there forever.”\n","\"Here come the Jews.\n","They don't like Farrakhan, so they call me Hitler.\n","Well, that's a good name.\n","Hitler was a very great man.\"\n","Would a Republican get a pass on meeting with a racist hate group leader?\n","Obviously not.\n","Don't expect it to condemn Rep. Davis' comments.\n","He was just saying what most of them think.\n","The media is happy to talk about anti-Semitism.\n","It just won't address left-wing anti-Semitism and racism.\n","\n","\n","I regard him as an outstanding human being who commands a following of individuals who are learned and articulate and he plays a big role in the lives of thousands and thousands and thousands and thousands of people,”\n","Would a Republican get a pass on meeting with a racist hate group leader?\n","Obviously not\n","Don't expect it to condemn Rep. Davis' comments.\n","He was just saying what most of them think\n","Farrakhan had praised Hitler and declared that the Jews, \"can't say 'Never Again' to God, because when he puts you in the ovens, you're there forever.”\n","\"Here come the Jews.\n","They don't like Farrakhan, so they call me Hitler.\n","Well, that's a good name.\n","Hitler was a very great man.\"\n","Loving Anti-Semite\n","The media is very interested in racism\n","The media is happy to talk about anti-Semitism\n","\n","----------------------------------------------------------------------------------------------------\n","article index: 29\n","burning\n","There are obviously certain things that the FBI and other investigators seem intent on covering up.\n","so why change the narrative to make it even more unbelievable?\n","What exactly do they want us to believe?\n","\n","\n","What exactly do they want us to believe?\n","There are obviously certain things that the FBI and other investigators seem intent on covering up\n","so why change the narrative to make it even more unbelievable?\n","\n","----------------------------------------------------------------------------------------------------\n","article index: 56\n","striking example\n","a widespread cover-up\n","stunning tower audio once\n","complete nonsense\n","authorities are actually actively covering up what really happened on\n","night.\n","flag,\n","the American people are clearly not being told the truth.\n","\n","\n","widespread cover-up\n","the American people are clearly not being told the truth\n","complete nonsense\n","authorities are actually actively covering up what really happened\n","striking example\n","stunning tower audio\n","\n","----------------------------------------------------------------------------------------------------\n","article index: 63\n","Deadly Plague Could MUTATE And Become Untreatable As It Spreads Globally\n","country’s worst outbreak in 50 years.\n","the deadly bacteria could mutate and become untreatable as it spreads across the globe.\n","high likelihood that this disease could spread globally\n","infected traveler\n","America, health officials\n","warning\n","killed more than\n","Madagascar could mutate and become untreatable.\n","while it would be rather easy for an advanced country to contain the disease in its current form, he fears that it could evolve into something far more dangerous.\n","to the Ebola outbreak.\n","“As with any disease, it’s a real worry that it mutates and become untreatable,”\n","devastated Europe’s population in\n","Airborne infections are difficult at best to control.\n","Ten African nations have already been put on alert that the plague could easily spread to their region of the globe.\n","spread.\n","\n","\n","Plague Could MUTATE And Become Untreatable As It Spreads Globally\n","the deadly bacteria could mutate and become untreatable\n","could mutate and become untreatable\n","he fears that it could evolve into something far more dangerous\n","it’s a real worry that it mutates and become untreatable,”\n","devastated\n","difficult at best\n","already been put on alert\n","\n","----------------------------------------------------------------------------------------------------\n","article index: 69\n","It Is ‘Inevitable’ The Plague Becomes Resistant To Drugs\n","black death,\n","Officials warn that it’s inevitable that this bacterial infection that’s infected over 2000 people will become resistant to antibiotics.\n","antibiotics resistance is inevitable and making this disease much more terrifying.\n","Once the bacteria is resistant,\n","Madagascar’s healthcare system will be unable to cope if the deadly plague outbreak continues to escalate,\n","fears hospitals will be unable to\n","“worst outbreak in 50 years.”\n","black death\n","Although the plague is responding well to antibiotics\n","now, drug resistance is also an increasing concern amongst experts who predict it will vastly accelerate the disease’s death toll.\n","“Fortunately in [the] plague, it has not developed much antibiotic resistance.\n","If that kicks in, the plague will be far, far scarier.\n","patients, antibiotic resistance is more or less inevitable.”\n","country\n","struggle\n","if cases continue to spiral.\n","experts\n","fear the healthcare system is on\n","brink of being overwhelmed.\n","it will be all but impossible to control and the health care system would certainly be unable to handle the outbreak at that point, making a global pandemic much more likely.\n","\n","\n","black death\n","It Is ‘Inevitable’ The Plague Becomes Resistant To Drugs\n","it’s inevitable that this bacterial infection\n","antibiotics resistance is inevitable\n","Madagascar’s healthcare system will be unable to cope if the deadly plague outbreak continues to escalate\n","the “worst outbreak in 50 years\n","black death\n","drug resistance is also an increasing concern\n","antibiotic resistance is more or less inevitable\n","making this disease much more terrifying\n","If that kicks in, the plague will be far, far scarier\n","making a global pandemic much more likely\n","\n","----------------------------------------------------------------------------------------------------\n","article index: 55\n","brave defenders of the status quo\n","confusion”\n","“To teach with such an intentional lack of clarity inevitably risks sinning against the Holy Spirit, the Spirit of truth.”\n","many bishops don’t speak out publicly for fear they will be “marginalized or worse.”\n","given the boot.\n","the most astonishing aspect\n","this little incident\n","completely blind\n","And it looks extremely bad.\n","irony\n","cheap and vulgar ritual humiliation\n","bully-boy Church\n","midget bishops and minicardinals compete\n","each other\n","episcopal bullies.\n","absolutely\n","Appointing bishops who “scandalize” believers with dubious “teaching\n","practice.”\n","impression they’ll be “marginalized or worse” if they speak out.\n","supreme shepherd.”\n","“I have done what I believe God wanted me to do,[1]”\n","has bolstered my own “Great Clarifier” theory,\n","“just how weak is the faith of many within the Church,”\n","harmful theological\n","pastoral views.”\n","he was indeed got rid of.\n","complete inability\n","be approved of by the “cool kids” in the Vatican,\n","his own theological brilliance\n","Signaling furiously with the trendy FrancisChurch buzzwords and even trendier blithering incoherence,\n","Presumably because adultery itself is no longer sinful.\n","evangelization”\n","adultery\n","sacrilege\n","poor, poor woman\n","been abandoned by the first husband,\n","“finds no other way out than to\n","oneself to a kind-hearted person,” … with whom, I guess, she has also no choice but to have sexual relations.\n","Because of kind-heartedness.\n","relativistic Zeitgeist,”\n","There\n","“different levels” of gravity,\n","has\n","“falsely elevated to the rank of a decisive question of Catholicism and a measure of ideological comparison in order to decide whether one is conservative or liberal, in favor or against the pope.”\n","even threatening to go into schism if they didn’t get their way[2].\n","lionized by\n","howling tantrums\n","\n","\n","I have done what I believe God wanted me to do,[\n","bolstered my own “Great Clarifier” theory\n","the poor, poor woman\n","brave defenders of the status quo\n","cheap and vulgar ritual humiliation\n","bully-boy Church\n","midget bishops and minicardinals\n","episcopal bullies\n","who “scandalize” believers\n","supreme shepherd.”\n","got rid of\n","the “cool kids” in the Vatican\n","Signaling furiously\n","with whom, I guess, she has also no choice but to have sexual relations.\n","Because of kind-heartedness\n","falsely elevated to the rank of a decisive question of Catholicism and a measure of ideological comparison in order to decide whether one is conservative or liberal, in favor or against the pope.”\n","howling tantrums\n","To teach with such an intentional lack of clarity inevitably risks sinning against the Holy Spirit, the Spirit of truth\n","don’t speak out publicly for fear they will be “marginalized or worse\n","given the boot\n","little incident\n","extremely bad\n","they’ll be “marginalized or worse” if they speak out\n","blithering incoherence\n","Presumably because adultery itself is no longer sinful\n","relativistic Zeitgeist\n","even threatening to go into schism if they didn’t get their way\n","lionized\n","\n","----------------------------------------------------------------------------------------------------\n","article index: 18\n","Barack Obama's reckless appeasement of the Iranian regime has enabled its rise as a hegemonic threat\n","as a threat\n","Obama turned his back on millions of dissidents\n","Obama precipitously removed the remaining U.S. combat troops from Iraq, giving rise to ISIS’s re-emergence in Iraq from its bases in Syria.\n","terrorists, turning Iraq into a virtual vassal state of the largest state sponsor of terrorism in the process.\n","Iran legitimized Iran's path to eventually becoming a nuclear-armed state,\n","“It’s a new monster.”\n","Hezbollah has American blood on its hands,\n","milquetoast\n","could actually accelerate the cycle of violence and perpetuate conflict rather than get us to a sustainable outcome.”\n","Whether the Trump administration follows through remains to be seen.\n","\n","\n","Barack Obama's reckless appeasement of the Iranian regime has enabled its rise as a hegemonic threat\n","disastrous\n","“It’s a new monster.”\n","milquetoast\n","turned his back on millions of dissidents\n","giving rise to ISIS’s re-emergence in Iraq\n","turning Iraq into a virtual vassal state of the largest state sponsor of terrorism\n","legitimized Iran's path to eventually becoming a nuclear-armed state\n","American blood\n","could actually accelerate the cycle of violence and perpetuate conflict rather than get us to a sustainable outcome\n","Whether the Trump administration follows through remains to be seen\n","\n","----------------------------------------------------------------------------------------------------\n","article index: 0\n","plague epidemic\n","\"The next transmission could be more pronounced or stronger,\"\n","\"plague in Madagascar behaved in a very, very different way this year.\"\n","He also pointed to the presence of the pneumonic version, which spreads more easily and is more virulent, in the latest outbreak.\n","warned that the danger was not over.\n","\"when (the plague) comes again it starts from more stock, and the magnitude in the next transmission could be higher than the one that we saw,\"\n","it could even spill over into neighbouring countries and beyond,\"\n","\n","\n","The next transmission could be more pronounced or stronger\n","when (the plague) comes again it starts from more stock, and the magnitude in the next transmission could be higher than the one that we saw\n","appeared\n","a very, very different\n","He also pointed to the presence of the pneumonic version, which spreads more easily and is more virulent, in the latest outbreak\n","but warned that the danger was not over\n","it could even spill over into neighbouring countries and beyond\n","\n","----------------------------------------------------------------------------------------------------\n","article index: 100\n","gross negligence\n","a massive cover-up of the truth, the F.B.I.\n","and LVMPD have failed to record the death of at least one shooting victim\n","that law enforcement investigators have never asked to see the footage.\n","“placed” outside of\n","Who was this victim?\n","Will the F.B.I.\n","and LVMPD please explain what in the Hell is going on here?\n","How was this victim overlooked by investigators but known by Intellihub?\n","Who was this victim?\n","Why were people getting haircuts at the crime scene?\n","How many more victims went ignored by investigators?\n","\n","\n","gross negligence\n","How was this victim overlooked by investigators but known by Intellihub?\n","Who was this victim?\n","a massive cover-up of the truth, the F.B.I.\n","and LVMPD\n","law enforcement investigators have never asked to see the footage\n","placed”\n","Will the F.B.I.\n","and LVMPD please explain what in the Hell is going on here?\n","How many more victims went ignored by investigators?\n","botched investigation\n","were people getting haircuts at the crime scene?\n","\n","----------------------------------------------------------------------------------------------------\n","article index: 73\n","How Do You Like Paying For Sexual Harassment Settlements from Your Congress, America?\n","How Do You Like Paying For Sexual Harassment Settlements from Your Congress, America?\n","Thank you!\n","they aren’t pretty.\n","That money has come from the taxpayers of course.\n","epidemic of sexual harassment\n","If such a law was instituted, I guarantee you that sexual harassment on Capitol Hill would come to a screeching halt.\n","For many in Congress, having so many attractive young women around is one of the key benefits of the job.\n","the men “have no self-control.” “Amongst\n","with the worst reputations.\n","“sex trade on Capitol Hill.”\n","It isn’t going to stop until we boot out the corrupt career politicians that are engaging in this type of behavior.\n","“grassroots deplorables”\n","The American people have a right to know,\n","\n","\n","the epidemic of sexual harassment\n","How Do You Like Paying For Sexual Harassment Settlements from Your Congress, America?\n","How Do You Like Paying For Sexual Harassment Settlements from Your Congress, America?\n","they aren’t pretty\n","That money has come from the taxpayers of course\n","If such a law was instituted, I guarantee you that sexual harassment on Capitol Hill would come to a screeching halt\n","For many in Congress, having so many attractive young women around is one of the key benefits of the job\n","the men “have no self-control.”\n","the lawmakers with the worst reputations\n","sex trade on Capitol Hill.”\n","It isn’t going to stop until we boot out the corrupt career politicians that are engaging in this type of behavior\n","grassroots deplorables”\n","The American people have a right to know\n","\n","----------------------------------------------------------------------------------------------------\n","article index: 117\n","the deadliest mass shooting in modern U.S. history\n","\n","\n","the deadliest mass shooting in modern U.S. history\n","\n","----------------------------------------------------------------------------------------------------\n","article index: 137\n","Sociology helped generate a whole range of fake new academic subjects while corrupting existing ones into a toxic stew of racism and meaningless jargon.\n","absolute ignorance.\n","a perfect storm of sociology stupidity.\n","Sociology.\n","You really don't need to know anything.\n","The professor, who has a PhD in philosophy...\n","Of course she does.\n","the age of, \"My truth\".\n","\n","\n","a perfect storm of sociology stupidity\n","Sociology.\n","You really don't need to know anything\n","my truth\n","Sociology helped generate a whole range of fake new academic subjects while corrupting existing ones into a toxic stew of racism and meaningless jargon\n","absolute ignorance\n","shocked\n","The professor, who has a PhD in philosophy...\n","Of course she does\n","the age of, \"My truth\n","\n","----------------------------------------------------------------------------------------------------\n","article index: 103\n","\n","\n","\n","----------------------------------------------------------------------------------------------------\n","article index: 46\n","Are\n","‘Dancing With Corpses’\n","“dancing with corpses.”\n","The local tradition is said to be one of the major causes of the spread of this disease.\n","Health officials suspect it’s no coincidence that the outbreak coincides with the time of year when families customarily exhume the remains of dead relatives,\n","ritual,\n","the bacteria can still be transmitted and contaminate whoever handles the body,”\n","Some locals believe the whole plague is some kind of a government conspiracy,\n","The plague is a lie,”\n","cash-strapped government is just exaggerating the problem to get money ahead of an election next year.\n","And it isn’t that anyone is putting this past a government to lie for profits,\n","\n","\n","People Are Literally ‘Dancing With Corpses’\n","dancing with corpses.”\n","The local tradition is said to be one of the major causes of the spread of this disease\n","Some locals believe the whole plague is some kind of a government conspiracy\n","Health officials suspect it’s no coincidence that the outbreak coincides with the time of year when families customarily exhume the remains of dead relatives\n","The plague is a lie\n","government is just exaggerating the problem to get money ahead of an election next year\n","it isn’t that anyone is putting this past a government to lie for profits\n","the bacteria can still be transmitted and contaminate whoever handles the body\n","cash-strapped\n","\n","----------------------------------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hB2ghTdQkIob","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6KYdIrkD8op0","colab_type":"code","colab":{}},"source":["import spacy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-FGiaHRmlel3","colab_type":"code","outputId":"4004129c-4365-4ca5-dc12-938346341974","executionInfo":{"status":"ok","timestamp":1582957129598,"user_tz":-330,"elapsed":1319,"user":{"displayName":"Paramansh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mANS3lCUfabnCwNFz8A_Mb-FC_uqCl9Y4r-zhTcvA=s64","userId":"05094200950482431055"}},"colab":{"base_uri":"https://localhost:8080/","height":210}},"source":["nlp = spacy.load(\"en_core_web_sm\")\n","doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n","\n","for token in doc:\n","    print(token.text,  token.pos_)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Apple PROPN\n","is VERB\n","looking VERB\n","at ADP\n","buying VERB\n","U.K. PROPN\n","startup NOUN\n","for ADP\n","$ SYM\n","1 NUM\n","billion NUM\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b2PqUgdKleue","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BIds5ge2le3I","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DRgZVwMAPrK-","colab_type":"text"},"source":["#GPT-2"]},{"cell_type":"code","metadata":{"id":"WU8kNdsqPtT5","colab_type":"code","outputId":"128e8737-9193-4d3f-a7e6-e4a6e31dd083","executionInfo":{"status":"ok","timestamp":1580213457072,"user_tz":-330,"elapsed":6157,"user":{"displayName":"Subham Kumar","photoUrl":"","userId":"15408684190797250143"}},"colab":{"base_uri":"https://localhost:8080/","height":63}},"source":["from transformers import GPT2Tokenizer, GPT2Model, GPT2PreTrainedModel\n","import torch\n","import torch.nn as nn"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Y6Ch6xAjkSLl","colab_type":"code","colab":{}},"source":["# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","# text = \"What is the fastest runningggggggggg car in the\"\n","# indexed_tokens = tokenizer.encode(text)\n","# print(indexed_tokens)\n","# print(tokenizer.decode([2491]))\n","# tokens_tensor = torch.tensor([indexed_tokens])\n","# print(tokens_tensor)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0h1KFoFqlxJB","colab_type":"code","outputId":"5e0860f9-cad9-4bb9-dda7-cb12d86516a6","executionInfo":{"status":"error","timestamp":1585246892986,"user_tz":-330,"elapsed":1765,"user":{"displayName":"Paramansh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFUNSFhHphbpc_SffpUNDNLqiLPYS3aiygkhnRTw=s64","userId":"05094200950482431055"}},"colab":{"base_uri":"https://localhost:8080/","height":231}},"source":["class GPT2ForTokenClassification(GPT2PreTrainedModel):\n","  def __init__(self,config):\n","    super().__init__(config)\n","    self.num_labels = config.num_labels\n","\n","    self.gpt2 = GPT2Model(config)\n","    self.dropout = nn.Dropout(config.resid_pdrop)\n","    self.classifier = nn.Linear(config.n_embd, config.num_labels)\n","    self.init_weights()\n","  \n","  def forward(self,input_ids=None,\n","              attention_mask=None,\n","              token_type_ids = None,\n","              position_ids = None,\n","              head_mask = None,\n","              input_embeds = None,\n","              labels = None,\n","              ):\n","    output = self.gpt2(\n","        input_ids,\n","        attention_mask = attention_mask,\n","        token_type_ids = token_type_ids,\n","        position_ids = position_ids,\n","        head_mask = head_mask,\n","        inputs_embeds = inputs_embeds, \n","    )\n","\n","    sequence_output = outputs[0]\n","    sequence_output = self.dropout(sequence_output)\n","    logits = self.classifier(sequence_output)\n","    outputs = (logits,) + output[2:]\n","    if labels is not None:\n","      loss_fct =  CrossEntropyLoss()\n","\n","      if attention_mask is not None:\n","        active_loss = attention_mask.view(-1)==1\n","        active_logits = logits.view(-1, self.num_labels)[active_loss]\n","        active_labels = labels.view(-1)[active_loss]\n","        loss = loss_fct(active_logits, active_labels)\n","      else:\n","        loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","      outputs = (loss,) + outputs\n","    \n","    return outputs\n","        \n","    \n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-31b02fc62670>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mGPT2ForTokenClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGPT2PreTrainedModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'GPT2PreTrainedModel' is not defined"]}]},{"cell_type":"code","metadata":{"id":"muelS5vqED1X","colab_type":"code","colab":{}},"source":["model = GPT2ForTokenClassification.from_pretrained('gpt2', num_labels=2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TjaffIXKE48W","colab_type":"code","outputId":"7c7ce076-2d9d-4dae-9a1e-e0c2bc8e4781","executionInfo":{"status":"ok","timestamp":1580213765612,"user_tz":-330,"elapsed":1031,"user":{"displayName":"Subham Kumar","photoUrl":"","userId":"15408684190797250143"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = model.cuda()\n","print(model)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["GPT2ForTokenClassification(\n","  (gpt2): GPT2Model(\n","    (wte): Embedding(50257, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UN17N0lRFB2H","colab_type":"code","colab":{}},"source":["gpt2tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"],"execution_count":0,"outputs":[]}]}